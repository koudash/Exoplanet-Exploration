{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>koi_disposition</th>\n",
       "      <th>koi_fpflag_nt</th>\n",
       "      <th>koi_fpflag_ss</th>\n",
       "      <th>koi_fpflag_co</th>\n",
       "      <th>koi_fpflag_ec</th>\n",
       "      <th>koi_period</th>\n",
       "      <th>koi_period_err1</th>\n",
       "      <th>koi_period_err2</th>\n",
       "      <th>koi_time0bk</th>\n",
       "      <th>koi_time0bk_err1</th>\n",
       "      <th>...</th>\n",
       "      <th>koi_steff_err2</th>\n",
       "      <th>koi_slogg</th>\n",
       "      <th>koi_slogg_err1</th>\n",
       "      <th>koi_slogg_err2</th>\n",
       "      <th>koi_srad</th>\n",
       "      <th>koi_srad_err1</th>\n",
       "      <th>koi_srad_err2</th>\n",
       "      <th>ra</th>\n",
       "      <th>dec</th>\n",
       "      <th>koi_kepmag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CONFIRMED</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>9.488036</td>\n",
       "      <td>2.775000e-05</td>\n",
       "      <td>-2.775000e-05</td>\n",
       "      <td>170.538750</td>\n",
       "      <td>0.002160</td>\n",
       "      <td>...</td>\n",
       "      <td>-81.0</td>\n",
       "      <td>4.467</td>\n",
       "      <td>0.064</td>\n",
       "      <td>-0.096</td>\n",
       "      <td>0.927</td>\n",
       "      <td>0.105</td>\n",
       "      <td>-0.061</td>\n",
       "      <td>291.93423</td>\n",
       "      <td>48.141651</td>\n",
       "      <td>15.347</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>CONFIRMED</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>54.418383</td>\n",
       "      <td>2.479000e-04</td>\n",
       "      <td>-2.479000e-04</td>\n",
       "      <td>162.513840</td>\n",
       "      <td>0.003520</td>\n",
       "      <td>...</td>\n",
       "      <td>-81.0</td>\n",
       "      <td>4.467</td>\n",
       "      <td>0.064</td>\n",
       "      <td>-0.096</td>\n",
       "      <td>0.927</td>\n",
       "      <td>0.105</td>\n",
       "      <td>-0.061</td>\n",
       "      <td>291.93423</td>\n",
       "      <td>48.141651</td>\n",
       "      <td>15.347</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>FALSE POSITIVE</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>19.899140</td>\n",
       "      <td>1.494000e-05</td>\n",
       "      <td>-1.494000e-05</td>\n",
       "      <td>175.850252</td>\n",
       "      <td>0.000581</td>\n",
       "      <td>...</td>\n",
       "      <td>-176.0</td>\n",
       "      <td>4.544</td>\n",
       "      <td>0.044</td>\n",
       "      <td>-0.176</td>\n",
       "      <td>0.868</td>\n",
       "      <td>0.233</td>\n",
       "      <td>-0.078</td>\n",
       "      <td>297.00482</td>\n",
       "      <td>48.134129</td>\n",
       "      <td>15.436</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>FALSE POSITIVE</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.736952</td>\n",
       "      <td>2.630000e-07</td>\n",
       "      <td>-2.630000e-07</td>\n",
       "      <td>170.307565</td>\n",
       "      <td>0.000115</td>\n",
       "      <td>...</td>\n",
       "      <td>-174.0</td>\n",
       "      <td>4.564</td>\n",
       "      <td>0.053</td>\n",
       "      <td>-0.168</td>\n",
       "      <td>0.791</td>\n",
       "      <td>0.201</td>\n",
       "      <td>-0.067</td>\n",
       "      <td>285.53461</td>\n",
       "      <td>48.285210</td>\n",
       "      <td>15.597</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>CONFIRMED</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2.525592</td>\n",
       "      <td>3.761000e-06</td>\n",
       "      <td>-3.761000e-06</td>\n",
       "      <td>171.595550</td>\n",
       "      <td>0.001130</td>\n",
       "      <td>...</td>\n",
       "      <td>-211.0</td>\n",
       "      <td>4.438</td>\n",
       "      <td>0.070</td>\n",
       "      <td>-0.210</td>\n",
       "      <td>1.046</td>\n",
       "      <td>0.334</td>\n",
       "      <td>-0.133</td>\n",
       "      <td>288.75488</td>\n",
       "      <td>48.226200</td>\n",
       "      <td>15.509</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 41 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  koi_disposition  koi_fpflag_nt  koi_fpflag_ss  koi_fpflag_co  koi_fpflag_ec  \\\n",
       "0       CONFIRMED              0              0              0              0   \n",
       "1       CONFIRMED              0              0              0              0   \n",
       "2  FALSE POSITIVE              0              1              0              0   \n",
       "3  FALSE POSITIVE              0              1              0              0   \n",
       "4       CONFIRMED              0              0              0              0   \n",
       "\n",
       "   koi_period  koi_period_err1  koi_period_err2  koi_time0bk  \\\n",
       "0    9.488036     2.775000e-05    -2.775000e-05   170.538750   \n",
       "1   54.418383     2.479000e-04    -2.479000e-04   162.513840   \n",
       "2   19.899140     1.494000e-05    -1.494000e-05   175.850252   \n",
       "3    1.736952     2.630000e-07    -2.630000e-07   170.307565   \n",
       "4    2.525592     3.761000e-06    -3.761000e-06   171.595550   \n",
       "\n",
       "   koi_time0bk_err1     ...      koi_steff_err2  koi_slogg  koi_slogg_err1  \\\n",
       "0          0.002160     ...               -81.0      4.467           0.064   \n",
       "1          0.003520     ...               -81.0      4.467           0.064   \n",
       "2          0.000581     ...              -176.0      4.544           0.044   \n",
       "3          0.000115     ...              -174.0      4.564           0.053   \n",
       "4          0.001130     ...              -211.0      4.438           0.070   \n",
       "\n",
       "   koi_slogg_err2  koi_srad  koi_srad_err1  koi_srad_err2         ra  \\\n",
       "0          -0.096     0.927          0.105         -0.061  291.93423   \n",
       "1          -0.096     0.927          0.105         -0.061  291.93423   \n",
       "2          -0.176     0.868          0.233         -0.078  297.00482   \n",
       "3          -0.168     0.791          0.201         -0.067  285.53461   \n",
       "4          -0.210     1.046          0.334         -0.133  288.75488   \n",
       "\n",
       "         dec  koi_kepmag  \n",
       "0  48.141651      15.347  \n",
       "1  48.141651      15.347  \n",
       "2  48.134129      15.436  \n",
       "3  48.285210      15.597  \n",
       "4  48.226200      15.509  \n",
       "\n",
       "[5 rows x 41 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read CSV Data\n",
    "df = pd.read_csv(\"../data/cumulative.csv\")\n",
    "# Remove unnecessary features\n",
    "df = df.drop(columns=[\"rowid\", \"kepid\", \"kepoi_name\", \"kepler_name\", \"koi_pdisposition\", \"koi_score\", \"koi_tce_delivname\"])\n",
    "# Drop the null columns where all values are null\n",
    "df = df.dropna(axis='columns', how='all')\n",
    "# Drop the null rows\n",
    "df = df.dropna()\n",
    "# Preview \"df\"\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color=\"navy\">Optimize Correlation Threshold to Remove Functionally Redundant Features</font>\n",
    "<i><font color=\"sky blue\"><strong>Optimization was applied in random forest (rf) model as rf does not require the distribution pattern of data<strong></font></i>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Column to be used as label\n",
    "target = df[\"koi_disposition\"]    \n",
    "\n",
    "# Transform categorical labels to numerical\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "target_encoder = LabelEncoder().fit(target.values)\n",
    "encd_target = target_encoder.transform(target.values)\n",
    "    \n",
    "# One-hot encoding labels\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "encd_target_categ = to_categorical(encd_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kouda\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\data.py:323: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by MinMaxScaler.\n",
      "  return self.partial_fit(X, y)\n",
      "C:\\Users\\kouda\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\data.py:323: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by MinMaxScaler.\n",
      "  return self.partial_fit(X, y)\n",
      "C:\\Users\\kouda\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\data.py:323: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by MinMaxScaler.\n",
      "  return self.partial_fit(X, y)\n",
      "C:\\Users\\kouda\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\data.py:323: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by MinMaxScaler.\n",
      "  return self.partial_fit(X, y)\n",
      "C:\\Users\\kouda\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\data.py:323: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by MinMaxScaler.\n",
      "  return self.partial_fit(X, y)\n",
      "C:\\Users\\kouda\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\data.py:323: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by MinMaxScaler.\n",
      "  return self.partial_fit(X, y)\n",
      "C:\\Users\\kouda\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\data.py:323: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by MinMaxScaler.\n",
      "  return self.partial_fit(X, y)\n",
      "C:\\Users\\kouda\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\data.py:323: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by MinMaxScaler.\n",
      "  return self.partial_fit(X, y)\n",
      "C:\\Users\\kouda\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\data.py:323: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by MinMaxScaler.\n",
      "  return self.partial_fit(X, y)\n",
      "C:\\Users\\kouda\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\data.py:323: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by MinMaxScaler.\n",
      "  return self.partial_fit(X, y)\n",
      "C:\\Users\\kouda\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\data.py:323: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by MinMaxScaler.\n",
      "  return self.partial_fit(X, y)\n",
      "C:\\Users\\kouda\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\data.py:323: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by MinMaxScaler.\n",
      "  return self.partial_fit(X, y)\n",
      "C:\\Users\\kouda\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\data.py:323: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by MinMaxScaler.\n",
      "  return self.partial_fit(X, y)\n",
      "C:\\Users\\kouda\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\data.py:323: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by MinMaxScaler.\n",
      "  return self.partial_fit(X, y)\n",
      "C:\\Users\\kouda\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\data.py:323: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by MinMaxScaler.\n",
      "  return self.partial_fit(X, y)\n",
      "C:\\Users\\kouda\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\data.py:323: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by MinMaxScaler.\n",
      "  return self.partial_fit(X, y)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# List to hold correlation threshold (corr_thold) to be tested in Random Forest model\n",
    "corr_thold_list = range(20, 100, 5)\n",
    "\n",
    "# Library to hold score info. for each corr_thold\n",
    "corr_thold_results = {\n",
    "    \"corr_thold\": [],\n",
    "    \"number of features\": [],\n",
    "    \"testing score\": []\n",
    "}\n",
    "\n",
    "# Iterate for each corr_thold\n",
    "for corr_thold in corr_thold_list:\n",
    "    \n",
    "    # Columns to be used as features\n",
    "    features = df.drop(\"koi_disposition\", axis=1)\n",
    "    # List for names of all columns from \"features\"\n",
    "    cols = features.columns\n",
    "    # List for names of functionally redudant columns to be deleted\n",
    "    col_del = []\n",
    "    \n",
    "    for i in range(len(cols)):\n",
    "        # If B and C are both closely correlated with A, appending cols[j] rather than cols[i] will delete both B and C \n",
    "        # with no exception even if they are not correlated to each other at all, which might compromise our model\n",
    "        # It has been tested that deleting \"cols[i]\" will yield a better score given the same correlation threshold\n",
    "        [col_del.append(cols[i]) for j in range(i) if abs(features[cols[i]].corr(features[cols[j]])) > corr_thold / 100]\n",
    "\n",
    "    # Delete functionally redundant columns\n",
    "    features = features.drop(columns=col_del)\n",
    "    \n",
    "    # Split date into train and test    \n",
    "    X_train, X_test, y_train, y_test = train_test_split(features, encd_target_categ, random_state=8)\n",
    "    \n",
    "    # Use MinMaxScaler for normalization as we are dealing with distance metrics        \n",
    "    X_scaler_mms = MinMaxScaler().fit(X_train)\n",
    "    X_train_scaled_mms = X_scaler_mms.transform(X_train)\n",
    "    X_test_scaled_mms = X_scaler_mms.transform(X_test)\n",
    "       \n",
    "    # Create random forest classifier\n",
    "    rf = RandomForestClassifier(n_estimators=200)\n",
    "    rf = rf.fit(X_train_scaled_mms, y_train)\n",
    "\n",
    "    # Append results to \"corr_thold_results\"\n",
    "    corr_thold_results[\"corr_thold\"].append(corr_thold / 100)\n",
    "    corr_thold_results[\"number of features\"].append(features.shape[1])\n",
    "    corr_thold_results[\"testing score\"].append(rf.score(X_test_scaled_mms, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Make plot for \"testing score\" and \"number of features\"\n",
    "fig, ax1 = plt.subplots()\n",
    "\n",
    "ax2 = ax1.twinx()\n",
    "ax1.plot(corr_thold_results[\"corr_thold\"], corr_thold_results[\"testing score\"], marker='o', color=\"g\")\n",
    "ax2.plot(corr_thold_results[\"corr_thold\"], corr_thold_results[\"number of features\"], marker=\"x\", color=\"b\")\n",
    "\n",
    "plt.axvline(x=0.45, linestyle='dashed', c=\"r\", alpha=0.5)\n",
    "\n",
    "ax1.set_xlabel(\"Correlation threshold\")\n",
    "ax1.set_ylabel(\"Testing score\", color=\"g\")\n",
    "ax2.set_ylabel(\"Number of features\", color=\"b\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Based on the chart, <span style=\"background-color:red; color:white\">correlation threshold at 0.45 with as few as 15 features</span> still retains the potential for optimized prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color=\"navy\">Prepare Features and Labels for Machine Learning Models</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['koi_fpflag_nt', 'koi_fpflag_ss', 'koi_fpflag_co', 'koi_period',\n",
       "       'koi_impact', 'koi_impact_err1', 'koi_duration', 'koi_depth',\n",
       "       'koi_depth_err1', 'koi_teq', 'koi_insol', 'koi_tce_plnt_num',\n",
       "       'koi_steff', 'ra', 'dec'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Set corr_thold at 0.45\n",
    "corr_thold = 45\n",
    "\n",
    "# Features used thereafter to build machine learning models (before deleting functionally redundant columns)\n",
    "features = df.drop(\"koi_disposition\", axis=1)\n",
    "\n",
    "# List for column names to be deleted due to high correlation with others\n",
    "col_del = []\n",
    "# List for names of all columns from \"features\"\n",
    "cols = features.columns\n",
    "\n",
    "for i in range(len(cols)):\n",
    "    # Append name of features (cols[i]) to \"col_del\" if high correlated column is found\n",
    "    [col_del.append(cols[i]) for j in range(i) if abs(features[cols[i]].corr(features[cols[j]])) > corr_thold / 100]\n",
    "\n",
    "# Delete functionally redundant columns\n",
    "features = features.drop(columns=col_del)\n",
    "\n",
    "# View names of remaining columns in features\n",
    "features.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**********\n",
      "feature name: koi_period\n",
      "skewness: 2.9096056442850604\n",
      "kurtosis: 8.575707227778738\n",
      "**********\n",
      "feature name: koi_impact\n",
      "skewness: 24.545626819012853\n",
      "kurtosis: 654.292256814103\n",
      "**********\n",
      "feature name: koi_impact_err1\n",
      "skewness: 6.312551243046779\n",
      "kurtosis: 40.330434371786815\n",
      "**********\n",
      "feature name: koi_duration\n",
      "skewness: 6.142732763305333\n",
      "kurtosis: 69.88306228640944\n",
      "**********\n",
      "feature name: koi_depth\n",
      "skewness: 5.339789447449275\n",
      "kurtosis: 39.95195255565689\n",
      "**********\n",
      "feature name: koi_depth_err1\n",
      "skewness: 90.88380242228578\n",
      "kurtosis: 8398.884284599475\n",
      "**********\n",
      "feature name: koi_teq\n",
      "skewness: 3.4534017756543443\n",
      "kurtosis: 27.91764996090529\n",
      "**********\n",
      "feature name: koi_insol\n",
      "skewness: 52.04085840580866\n",
      "kurtosis: 3129.058646282767\n",
      "**********\n",
      "feature name: koi_tce_plnt_num\n",
      "skewness: 3.650882561012579\n",
      "kurtosis: 16.94099602738316\n",
      "**********\n",
      "feature name: koi_steff\n",
      "skewness: 0.7542120521681619\n",
      "kurtosis: 8.074889842710324\n"
     ]
    }
   ],
   "source": [
    "# Iterate for each column in features\n",
    "for col in features.columns:\n",
    "    \n",
    "    # Check for skewness and kurtosis\n",
    "    skewness = stats.describe(features[col])[4]\n",
    "    kurtosis = stats.describe(features[col])[5]\n",
    "    \n",
    "    # Print out column info if either skewness or kurtosis is larger than 3\n",
    "    if (skewness > 3) or (kurtosis > 3):    \n",
    "        print(\"*\" * 10)\n",
    "        print(f\"feature name: {col}\")\n",
    "        print(f\"skewness: {skewness}\")\n",
    "        print(f\"kurtosis: {kurtosis}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Based on skewness and kurtosis study, there are two thirds columns in features whose data are not normally distributed (>3). In considering data distribution, we will use random forest, SVM, KNN, and Neural Network models thereafter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up train and test data for all machine learning models to be built in this project\n",
    "# Split date into train and test\n",
    "X_train, X_test, y_train, y_test = train_test_split(features, encd_target, random_state=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kouda\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\data.py:323: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by MinMaxScaler.\n",
      "  return self.partial_fit(X, y)\n"
     ]
    }
   ],
   "source": [
    "# Regression models will not be used due to data distribution\n",
    "# MinMaxScaler is preferred over StandardScaler for scaling features\n",
    "# In this project, StandardScaler scored exactly the same as MinMaxScaler at corr_thold=0.45\n",
    "X_scaler_mms = MinMaxScaler().fit(X_train)\n",
    "\n",
    "X_train_scaled_mms = X_scaler_mms.transform(X_train)\n",
    "X_test_scaled_mms = X_scaler_mms.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color=\"navy\">Random Forest Model</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kouda\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\forest.py:246: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "# Create random forest classifier\n",
    "rf = RandomForestClassifier()\n",
    "\n",
    "# Fit model with train data\n",
    "rf = rf.fit(X_train_scaled_mms, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Data Score: 0.9926806953339433\n",
      "Testing Data Score: 0.8700823421774931\n"
     ]
    }
   ],
   "source": [
    "# Scores for train and test data\n",
    "print(f\"Training Data Score: {rf.score(X_train_scaled_mms, y_train)}\")\n",
    "print(f\"Testing Data Score: {rf.score(X_test_scaled_mms, y_test)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create GridSearch estimator along with \"n_estimators\" and \"max_features\" parameters for hyperparameter tuning of the model\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "# Set up tuning parameters\n",
    "param_grid_rf = {'n_estimators': [50, 200, 500, 800],\n",
    "                 'criterion': [\"gini\", \"entropy\"],\n",
    "                 'max_features': [\"sqrt\", \"log2\"]\n",
    "                 }\n",
    "              \n",
    "grid_rf = GridSearchCV(rf, param_grid_rf, verbose=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kouda\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py:2053: FutureWarning: You should specify a value for 'cv' instead of relying on the default value. The default value will change from 3 to 5 in version 0.22.\n",
      "  warnings.warn(CV_WARNING, FutureWarning)\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 16 candidates, totalling 48 fits\n",
      "[CV] criterion=gini, max_features=sqrt, n_estimators=50 ..............\n",
      "[CV]  criterion=gini, max_features=sqrt, n_estimators=50, score=0.8770004572473709, total=   0.7s\n",
      "[CV] criterion=gini, max_features=sqrt, n_estimators=50 ..............\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.8s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  criterion=gini, max_features=sqrt, n_estimators=50, score=0.8756287151348879, total=   0.7s\n",
      "[CV] criterion=gini, max_features=sqrt, n_estimators=50 ..............\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    1.6s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  criterion=gini, max_features=sqrt, n_estimators=50, score=0.8681318681318682, total=   0.7s\n",
      "[CV] criterion=gini, max_features=sqrt, n_estimators=200 .............\n",
      "[CV]  criterion=gini, max_features=sqrt, n_estimators=200, score=0.8806584362139918, total=   3.1s\n",
      "[CV] criterion=gini, max_features=sqrt, n_estimators=200 .............\n",
      "[CV]  criterion=gini, max_features=sqrt, n_estimators=200, score=0.8774577046181985, total=   3.1s\n",
      "[CV] criterion=gini, max_features=sqrt, n_estimators=200 .............\n",
      "[CV]  criterion=gini, max_features=sqrt, n_estimators=200, score=0.8653846153846154, total=   3.1s\n",
      "[CV] criterion=gini, max_features=sqrt, n_estimators=500 .............\n",
      "[CV]  criterion=gini, max_features=sqrt, n_estimators=500, score=0.879286694101509, total=   7.9s\n",
      "[CV] criterion=gini, max_features=sqrt, n_estimators=500 .............\n",
      "[CV]  criterion=gini, max_features=sqrt, n_estimators=500, score=0.8820301783264746, total=   7.9s\n",
      "[CV] criterion=gini, max_features=sqrt, n_estimators=500 .............\n",
      "[CV]  criterion=gini, max_features=sqrt, n_estimators=500, score=0.8704212454212454, total=   7.9s\n",
      "[CV] criterion=gini, max_features=sqrt, n_estimators=800 .............\n",
      "[CV]  criterion=gini, max_features=sqrt, n_estimators=800, score=0.879286694101509, total=  12.8s\n",
      "[CV] criterion=gini, max_features=sqrt, n_estimators=800 .............\n",
      "[CV]  criterion=gini, max_features=sqrt, n_estimators=800, score=0.879286694101509, total=  12.8s\n",
      "[CV] criterion=gini, max_features=sqrt, n_estimators=800 .............\n",
      "[CV]  criterion=gini, max_features=sqrt, n_estimators=800, score=0.8708791208791209, total=  12.7s\n",
      "[CV] criterion=gini, max_features=log2, n_estimators=50 ..............\n",
      "[CV]  criterion=gini, max_features=log2, n_estimators=50, score=0.869684499314129, total=   0.7s\n",
      "[CV] criterion=gini, max_features=log2, n_estimators=50 ..............\n",
      "[CV]  criterion=gini, max_features=log2, n_estimators=50, score=0.8760859625057156, total=   0.7s\n",
      "[CV] criterion=gini, max_features=log2, n_estimators=50 ..............\n",
      "[CV]  criterion=gini, max_features=log2, n_estimators=50, score=0.8717948717948718, total=   0.7s\n",
      "[CV] criterion=gini, max_features=log2, n_estimators=200 .............\n",
      "[CV]  criterion=gini, max_features=log2, n_estimators=200, score=0.8788294467306813, total=   2.9s\n",
      "[CV] criterion=gini, max_features=log2, n_estimators=200 .............\n",
      "[CV]  criterion=gini, max_features=log2, n_estimators=200, score=0.879286694101509, total=   3.0s\n",
      "[CV] criterion=gini, max_features=log2, n_estimators=200 .............\n",
      "[CV]  criterion=gini, max_features=log2, n_estimators=200, score=0.8713369963369964, total=   3.1s\n",
      "[CV] criterion=gini, max_features=log2, n_estimators=500 .............\n",
      "[CV]  criterion=gini, max_features=log2, n_estimators=500, score=0.879286694101509, total=   7.9s\n",
      "[CV] criterion=gini, max_features=log2, n_estimators=500 .............\n",
      "[CV]  criterion=gini, max_features=log2, n_estimators=500, score=0.8788294467306813, total=   7.8s\n",
      "[CV] criterion=gini, max_features=log2, n_estimators=500 .............\n",
      "[CV]  criterion=gini, max_features=log2, n_estimators=500, score=0.8713369963369964, total=   7.8s\n",
      "[CV] criterion=gini, max_features=log2, n_estimators=800 .............\n",
      "[CV]  criterion=gini, max_features=log2, n_estimators=800, score=0.8765432098765432, total=  12.7s\n",
      "[CV] criterion=gini, max_features=log2, n_estimators=800 .............\n",
      "[CV]  criterion=gini, max_features=log2, n_estimators=800, score=0.8788294467306813, total=  12.7s\n",
      "[CV] criterion=gini, max_features=log2, n_estimators=800 .............\n",
      "[CV]  criterion=gini, max_features=log2, n_estimators=800, score=0.8745421245421245, total=  12.6s\n",
      "[CV] criterion=entropy, max_features=sqrt, n_estimators=50 ...........\n",
      "[CV]  criterion=entropy, max_features=sqrt, n_estimators=50, score=0.8760859625057156, total=   1.2s\n",
      "[CV] criterion=entropy, max_features=sqrt, n_estimators=50 ...........\n",
      "[CV]  criterion=entropy, max_features=sqrt, n_estimators=50, score=0.871970736168267, total=   1.2s\n",
      "[CV] criterion=entropy, max_features=sqrt, n_estimators=50 ...........\n",
      "[CV]  criterion=entropy, max_features=sqrt, n_estimators=50, score=0.8617216117216118, total=   1.1s\n",
      "[CV] criterion=entropy, max_features=sqrt, n_estimators=200 ..........\n",
      "[CV]  criterion=entropy, max_features=sqrt, n_estimators=200, score=0.877914951989026, total=   5.0s\n",
      "[CV] criterion=entropy, max_features=sqrt, n_estimators=200 ..........\n",
      "[CV]  criterion=entropy, max_features=sqrt, n_estimators=200, score=0.8770004572473709, total=   5.0s\n",
      "[CV] criterion=entropy, max_features=sqrt, n_estimators=200 ..........\n",
      "[CV]  criterion=entropy, max_features=sqrt, n_estimators=200, score=0.8708791208791209, total=   4.9s\n",
      "[CV] criterion=entropy, max_features=sqrt, n_estimators=500 ..........\n",
      "[CV]  criterion=entropy, max_features=sqrt, n_estimators=500, score=0.881572930955647, total=  12.6s\n",
      "[CV] criterion=entropy, max_features=sqrt, n_estimators=500 ..........\n",
      "[CV]  criterion=entropy, max_features=sqrt, n_estimators=500, score=0.879286694101509, total=  12.5s\n",
      "[CV] criterion=entropy, max_features=sqrt, n_estimators=500 ..........\n",
      "[CV]  criterion=entropy, max_features=sqrt, n_estimators=500, score=0.8704212454212454, total=  12.4s\n",
      "[CV] criterion=entropy, max_features=sqrt, n_estimators=800 ..........\n",
      "[CV]  criterion=entropy, max_features=sqrt, n_estimators=800, score=0.8802011888431641, total=  20.2s\n",
      "[CV] criterion=entropy, max_features=sqrt, n_estimators=800 ..........\n",
      "[CV]  criterion=entropy, max_features=sqrt, n_estimators=800, score=0.8774577046181985, total=  20.3s\n",
      "[CV] criterion=entropy, max_features=sqrt, n_estimators=800 ..........\n",
      "[CV]  criterion=entropy, max_features=sqrt, n_estimators=800, score=0.8690476190476191, total=  20.1s\n",
      "[CV] criterion=entropy, max_features=log2, n_estimators=50 ...........\n",
      "[CV]  criterion=entropy, max_features=log2, n_estimators=50, score=0.8770004572473709, total=   1.2s\n",
      "[CV] criterion=entropy, max_features=log2, n_estimators=50 ...........\n",
      "[CV]  criterion=entropy, max_features=log2, n_estimators=50, score=0.8760859625057156, total=   1.2s\n",
      "[CV] criterion=entropy, max_features=log2, n_estimators=50 ...........\n",
      "[CV]  criterion=entropy, max_features=log2, n_estimators=50, score=0.8608058608058609, total=   1.2s\n",
      "[CV] criterion=entropy, max_features=log2, n_estimators=200 ..........\n",
      "[CV]  criterion=entropy, max_features=log2, n_estimators=200, score=0.8783721993598537, total=   4.9s\n",
      "[CV] criterion=entropy, max_features=log2, n_estimators=200 ..........\n",
      "[CV]  criterion=entropy, max_features=log2, n_estimators=200, score=0.8802011888431641, total=   4.9s\n",
      "[CV] criterion=entropy, max_features=log2, n_estimators=200 ..........\n",
      "[CV]  criterion=entropy, max_features=log2, n_estimators=200, score=0.8658424908424909, total=   5.0s\n",
      "[CV] criterion=entropy, max_features=log2, n_estimators=500 ..........\n",
      "[CV]  criterion=entropy, max_features=log2, n_estimators=500, score=0.8802011888431641, total=  12.6s\n",
      "[CV] criterion=entropy, max_features=log2, n_estimators=500 ..........\n",
      "[CV]  criterion=entropy, max_features=log2, n_estimators=500, score=0.8774577046181985, total=  12.6s\n",
      "[CV] criterion=entropy, max_features=log2, n_estimators=500 ..........\n",
      "[CV]  criterion=entropy, max_features=log2, n_estimators=500, score=0.8695054945054945, total=  12.6s\n",
      "[CV] criterion=entropy, max_features=log2, n_estimators=800 ..........\n",
      "[CV]  criterion=entropy, max_features=log2, n_estimators=800, score=0.8820301783264746, total=  20.3s\n",
      "[CV] criterion=entropy, max_features=log2, n_estimators=800 ..........\n",
      "[CV]  criterion=entropy, max_features=log2, n_estimators=800, score=0.881572930955647, total=  20.4s\n",
      "[CV] criterion=entropy, max_features=log2, n_estimators=800 ..........\n",
      "[CV]  criterion=entropy, max_features=log2, n_estimators=800, score=0.8676739926739927, total=  19.8s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  48 out of  48 | elapsed:  6.8min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv='warn', error_score='raise-deprecating',\n",
       "       estimator=RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=None,\n",
       "            oob_score=False, random_state=None, verbose=0,\n",
       "            warm_start=False),\n",
       "       fit_params=None, iid='warn', n_jobs=None,\n",
       "       param_grid={'n_estimators': [50, 200, 500, 800], 'criterion': ['gini', 'entropy'], 'max_features': ['sqrt', 'log2']},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
       "       scoring=None, verbose=3)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fit rf model using grid search estimator\n",
    "grid_rf.fit(X_train_scaled_mms, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'criterion': 'gini', 'max_features': 'sqrt', 'n_estimators': 500}\n"
     ]
    }
   ],
   "source": [
    " # List the best parameters for this dataset\n",
    "print(grid_rf.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Data Score: 1.0\n",
      "Testing Data Score: 0.8911253430924062\n"
     ]
    }
   ],
   "source": [
    "# Scores for train and test data after hyperparameter tuning of the model\n",
    "print(f\"Training Data Score: {grid_rf.score(X_train_scaled_mms, y_train)}\")\n",
    "print(f\"Testing Data Score: {grid_rf.score(X_test_scaled_mms, y_test)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.78      0.78       510\n",
      "           1       0.83      0.82      0.83       587\n",
      "           2       0.97      0.98      0.98      1089\n",
      "\n",
      "   micro avg       0.89      0.89      0.89      2186\n",
      "   macro avg       0.86      0.86      0.86      2186\n",
      "weighted avg       0.89      0.89      0.89      2186\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Calculate classification report\n",
    "print(classification_report(\n",
    "    y_test, grid_rf.predict(X_test_scaled_mms), target_names=[\"0\", \"1\", \"2\"]\n",
    "))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>target_test</th>\n",
       "      <th>target_predicted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>FALSE POSITIVE</td>\n",
       "      <td>FALSE POSITIVE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>FALSE POSITIVE</td>\n",
       "      <td>FALSE POSITIVE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>CONFIRMED</td>\n",
       "      <td>CONFIRMED</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>CANDIDATE</td>\n",
       "      <td>CANDIDATE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>FALSE POSITIVE</td>\n",
       "      <td>FALSE POSITIVE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>CONFIRMED</td>\n",
       "      <td>CONFIRMED</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>CANDIDATE</td>\n",
       "      <td>CANDIDATE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>FALSE POSITIVE</td>\n",
       "      <td>FALSE POSITIVE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>FALSE POSITIVE</td>\n",
       "      <td>FALSE POSITIVE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>FALSE POSITIVE</td>\n",
       "      <td>CANDIDATE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>CONFIRMED</td>\n",
       "      <td>CONFIRMED</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>CANDIDATE</td>\n",
       "      <td>CANDIDATE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>FALSE POSITIVE</td>\n",
       "      <td>FALSE POSITIVE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>CONFIRMED</td>\n",
       "      <td>CONFIRMED</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>CANDIDATE</td>\n",
       "      <td>CANDIDATE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>CANDIDATE</td>\n",
       "      <td>CONFIRMED</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       target_test target_predicted\n",
       "0   FALSE POSITIVE   FALSE POSITIVE\n",
       "1   FALSE POSITIVE   FALSE POSITIVE\n",
       "2        CONFIRMED        CONFIRMED\n",
       "3        CANDIDATE        CANDIDATE\n",
       "4   FALSE POSITIVE   FALSE POSITIVE\n",
       "5        CONFIRMED        CONFIRMED\n",
       "6        CANDIDATE        CANDIDATE\n",
       "7   FALSE POSITIVE   FALSE POSITIVE\n",
       "8   FALSE POSITIVE   FALSE POSITIVE\n",
       "9   FALSE POSITIVE        CANDIDATE\n",
       "10       CONFIRMED        CONFIRMED\n",
       "11       CANDIDATE        CANDIDATE\n",
       "12  FALSE POSITIVE   FALSE POSITIVE\n",
       "13       CONFIRMED        CONFIRMED\n",
       "14       CANDIDATE        CANDIDATE\n",
       "15       CANDIDATE        CONFIRMED"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# DataFrame for test and predicted data\n",
    "target_pred_test_rf = pd.DataFrame({\n",
    "    \"target_test\": target_encoder.inverse_transform(y_test),\n",
    "    \"target_predicted\": target_encoder.inverse_transform(grid_rf.predict(X_test_scaled_mms))\n",
    "})\n",
    "\n",
    "# Preview \"target_pred_test_rf\"\n",
    "target_pred_test_rf.head(16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['../data/models/kepler_rf_model.h5']"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Save model as .h5 file\n",
    "from sklearn.externals import joblib\n",
    "joblib.dump(grid_rf.best_estimator_, '../models/kepler_rf_model.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color=\"navy\">SVM Model</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kouda\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
       "  decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
       "  kernel='rbf', max_iter=-1, probability=False, random_state=None,\n",
       "  shrinking=True, tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Support vector machine linear classifier\n",
    "from sklearn.svm import SVC\n",
    "# Create SVM classifier\n",
    "svm = SVC()\n",
    "# Fit model with train data\n",
    "svm.fit(X_train_scaled_mms, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Data Score: 0.786062824031717\n",
      "Testing Data Score: 0.7964318389752973\n"
     ]
    }
   ],
   "source": [
    "# Scores for train and test data\n",
    "print(f\"Training Data Score: {svm.score(X_train_scaled_mms, y_train)}\")\n",
    "print(f\"Testing Data Score: {svm.score(X_test_scaled_mms, y_test)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up tuning parameters\n",
    "param_grid_svm = {'C': [0.1, 1, 5, 10, 50],\n",
    "                  'kernel': [\"linear\", \"poly\", \"rbf\", \"sigmoid\"],\n",
    "                  'gamma': [0.0001, 0.0005, 0.001, 0.005],\n",
    "                 }\n",
    "              \n",
    "grid_svm = GridSearchCV(svm, param_grid_svm, verbose=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kouda\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py:2053: FutureWarning: You should specify a value for 'cv' instead of relying on the default value. The default value will change from 3 to 5 in version 0.22.\n",
      "  warnings.warn(CV_WARNING, FutureWarning)\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 80 candidates, totalling 240 fits\n",
      "[CV] C=0.1, gamma=0.0001, kernel=linear ..............................\n",
      "[CV]  C=0.1, gamma=0.0001, kernel=linear, score=0.7832647462277091, total=   0.1s\n",
      "[CV] C=0.1, gamma=0.0001, kernel=linear ..............................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.3s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  C=0.1, gamma=0.0001, kernel=linear, score=0.7722908093278463, total=   0.1s\n",
      "[CV] C=0.1, gamma=0.0001, kernel=linear ..............................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    0.7s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  C=0.1, gamma=0.0001, kernel=linear, score=0.7756410256410257, total=   0.1s\n",
      "[CV] C=0.1, gamma=0.0001, kernel=poly ................................\n",
      "[CV]  C=0.1, gamma=0.0001, kernel=poly, score=0.4983996342021033, total=   0.6s\n",
      "[CV] C=0.1, gamma=0.0001, kernel=poly ................................\n",
      "[CV]  C=0.1, gamma=0.0001, kernel=poly, score=0.4983996342021033, total=   0.5s\n",
      "[CV] C=0.1, gamma=0.0001, kernel=poly ................................\n",
      "[CV]  C=0.1, gamma=0.0001, kernel=poly, score=0.49862637362637363, total=   0.5s\n",
      "[CV] C=0.1, gamma=0.0001, kernel=rbf .................................\n",
      "[CV]  C=0.1, gamma=0.0001, kernel=rbf, score=0.4983996342021033, total=   0.8s\n",
      "[CV] C=0.1, gamma=0.0001, kernel=rbf .................................\n",
      "[CV]  C=0.1, gamma=0.0001, kernel=rbf, score=0.4983996342021033, total=   0.9s\n",
      "[CV] C=0.1, gamma=0.0001, kernel=rbf .................................\n",
      "[CV]  C=0.1, gamma=0.0001, kernel=rbf, score=0.49862637362637363, total=   0.8s\n",
      "[CV] C=0.1, gamma=0.0001, kernel=sigmoid .............................\n",
      "[CV]  C=0.1, gamma=0.0001, kernel=sigmoid, score=0.4983996342021033, total=   0.7s\n",
      "[CV] C=0.1, gamma=0.0001, kernel=sigmoid .............................\n",
      "[CV]  C=0.1, gamma=0.0001, kernel=sigmoid, score=0.4983996342021033, total=   0.7s\n",
      "[CV] C=0.1, gamma=0.0001, kernel=sigmoid .............................\n",
      "[CV]  C=0.1, gamma=0.0001, kernel=sigmoid, score=0.49862637362637363, total=   0.7s\n",
      "[CV] C=0.1, gamma=0.0005, kernel=linear ..............................\n",
      "[CV]  C=0.1, gamma=0.0005, kernel=linear, score=0.7832647462277091, total=   0.1s\n",
      "[CV] C=0.1, gamma=0.0005, kernel=linear ..............................\n",
      "[CV]  C=0.1, gamma=0.0005, kernel=linear, score=0.7722908093278463, total=   0.1s\n",
      "[CV] C=0.1, gamma=0.0005, kernel=linear ..............................\n",
      "[CV]  C=0.1, gamma=0.0005, kernel=linear, score=0.7756410256410257, total=   0.1s\n",
      "[CV] C=0.1, gamma=0.0005, kernel=poly ................................\n",
      "[CV]  C=0.1, gamma=0.0005, kernel=poly, score=0.4983996342021033, total=   0.5s\n",
      "[CV] C=0.1, gamma=0.0005, kernel=poly ................................\n",
      "[CV]  C=0.1, gamma=0.0005, kernel=poly, score=0.4983996342021033, total=   0.5s\n",
      "[CV] C=0.1, gamma=0.0005, kernel=poly ................................\n",
      "[CV]  C=0.1, gamma=0.0005, kernel=poly, score=0.49862637362637363, total=   0.5s\n",
      "[CV] C=0.1, gamma=0.0005, kernel=rbf .................................\n",
      "[CV]  C=0.1, gamma=0.0005, kernel=rbf, score=0.4983996342021033, total=   0.8s\n",
      "[CV] C=0.1, gamma=0.0005, kernel=rbf .................................\n",
      "[CV]  C=0.1, gamma=0.0005, kernel=rbf, score=0.4983996342021033, total=   0.8s\n",
      "[CV] C=0.1, gamma=0.0005, kernel=rbf .................................\n",
      "[CV]  C=0.1, gamma=0.0005, kernel=rbf, score=0.49862637362637363, total=   0.8s\n",
      "[CV] C=0.1, gamma=0.0005, kernel=sigmoid .............................\n",
      "[CV]  C=0.1, gamma=0.0005, kernel=sigmoid, score=0.4983996342021033, total=   0.7s\n",
      "[CV] C=0.1, gamma=0.0005, kernel=sigmoid .............................\n",
      "[CV]  C=0.1, gamma=0.0005, kernel=sigmoid, score=0.4983996342021033, total=   0.7s\n",
      "[CV] C=0.1, gamma=0.0005, kernel=sigmoid .............................\n",
      "[CV]  C=0.1, gamma=0.0005, kernel=sigmoid, score=0.49862637362637363, total=   0.7s\n",
      "[CV] C=0.1, gamma=0.001, kernel=linear ...............................\n",
      "[CV]  C=0.1, gamma=0.001, kernel=linear, score=0.7832647462277091, total=   0.1s\n",
      "[CV] C=0.1, gamma=0.001, kernel=linear ...............................\n",
      "[CV]  C=0.1, gamma=0.001, kernel=linear, score=0.7722908093278463, total=   0.1s\n",
      "[CV] C=0.1, gamma=0.001, kernel=linear ...............................\n",
      "[CV]  C=0.1, gamma=0.001, kernel=linear, score=0.7756410256410257, total=   0.1s\n",
      "[CV] C=0.1, gamma=0.001, kernel=poly .................................\n",
      "[CV]  C=0.1, gamma=0.001, kernel=poly, score=0.4983996342021033, total=   0.5s\n",
      "[CV] C=0.1, gamma=0.001, kernel=poly .................................\n",
      "[CV]  C=0.1, gamma=0.001, kernel=poly, score=0.4983996342021033, total=   0.5s\n",
      "[CV] C=0.1, gamma=0.001, kernel=poly .................................\n",
      "[CV]  C=0.1, gamma=0.001, kernel=poly, score=0.49862637362637363, total=   0.5s\n",
      "[CV] C=0.1, gamma=0.001, kernel=rbf ..................................\n",
      "[CV]  C=0.1, gamma=0.001, kernel=rbf, score=0.4983996342021033, total=   0.8s\n",
      "[CV] C=0.1, gamma=0.001, kernel=rbf ..................................\n",
      "[CV]  C=0.1, gamma=0.001, kernel=rbf, score=0.4983996342021033, total=   0.8s\n",
      "[CV] C=0.1, gamma=0.001, kernel=rbf ..................................\n",
      "[CV]  C=0.1, gamma=0.001, kernel=rbf, score=0.49862637362637363, total=   0.8s\n",
      "[CV] C=0.1, gamma=0.001, kernel=sigmoid ..............................\n",
      "[CV]  C=0.1, gamma=0.001, kernel=sigmoid, score=0.4983996342021033, total=   0.7s\n",
      "[CV] C=0.1, gamma=0.001, kernel=sigmoid ..............................\n",
      "[CV]  C=0.1, gamma=0.001, kernel=sigmoid, score=0.4983996342021033, total=   0.7s\n",
      "[CV] C=0.1, gamma=0.001, kernel=sigmoid ..............................\n",
      "[CV]  C=0.1, gamma=0.001, kernel=sigmoid, score=0.49862637362637363, total=   0.7s\n",
      "[CV] C=0.1, gamma=0.005, kernel=linear ...............................\n",
      "[CV]  C=0.1, gamma=0.005, kernel=linear, score=0.7832647462277091, total=   0.1s\n",
      "[CV] C=0.1, gamma=0.005, kernel=linear ...............................\n",
      "[CV]  C=0.1, gamma=0.005, kernel=linear, score=0.7722908093278463, total=   0.1s\n",
      "[CV] C=0.1, gamma=0.005, kernel=linear ...............................\n",
      "[CV]  C=0.1, gamma=0.005, kernel=linear, score=0.7756410256410257, total=   0.1s\n",
      "[CV] C=0.1, gamma=0.005, kernel=poly .................................\n",
      "[CV]  C=0.1, gamma=0.005, kernel=poly, score=0.4983996342021033, total=   0.5s\n",
      "[CV] C=0.1, gamma=0.005, kernel=poly .................................\n",
      "[CV]  C=0.1, gamma=0.005, kernel=poly, score=0.4983996342021033, total=   0.5s\n",
      "[CV] C=0.1, gamma=0.005, kernel=poly .................................\n",
      "[CV]  C=0.1, gamma=0.005, kernel=poly, score=0.49862637362637363, total=   0.5s\n",
      "[CV] C=0.1, gamma=0.005, kernel=rbf ..................................\n",
      "[CV]  C=0.1, gamma=0.005, kernel=rbf, score=0.4983996342021033, total=   0.8s\n",
      "[CV] C=0.1, gamma=0.005, kernel=rbf ..................................\n",
      "[CV]  C=0.1, gamma=0.005, kernel=rbf, score=0.4983996342021033, total=   0.8s\n",
      "[CV] C=0.1, gamma=0.005, kernel=rbf ..................................\n",
      "[CV]  C=0.1, gamma=0.005, kernel=rbf, score=0.49862637362637363, total=   0.8s\n",
      "[CV] C=0.1, gamma=0.005, kernel=sigmoid ..............................\n",
      "[CV]  C=0.1, gamma=0.005, kernel=sigmoid, score=0.4983996342021033, total=   0.8s\n",
      "[CV] C=0.1, gamma=0.005, kernel=sigmoid ..............................\n",
      "[CV]  C=0.1, gamma=0.005, kernel=sigmoid, score=0.4983996342021033, total=   0.7s\n",
      "[CV] C=0.1, gamma=0.005, kernel=sigmoid ..............................\n",
      "[CV]  C=0.1, gamma=0.005, kernel=sigmoid, score=0.49862637362637363, total=   0.7s\n",
      "[CV] C=1, gamma=0.0001, kernel=linear ................................\n",
      "[CV]  C=1, gamma=0.0001, kernel=linear, score=0.790580704160951, total=   0.1s\n",
      "[CV] C=1, gamma=0.0001, kernel=linear ................................\n",
      "[CV]  C=1, gamma=0.0001, kernel=linear, score=0.7988111568358482, total=   0.1s\n",
      "[CV] C=1, gamma=0.0001, kernel=linear ................................\n",
      "[CV]  C=1, gamma=0.0001, kernel=linear, score=0.7756410256410257, total=   0.1s\n",
      "[CV] C=1, gamma=0.0001, kernel=poly ..................................\n",
      "[CV]  C=1, gamma=0.0001, kernel=poly, score=0.4983996342021033, total=   0.5s\n",
      "[CV] C=1, gamma=0.0001, kernel=poly ..................................\n",
      "[CV]  C=1, gamma=0.0001, kernel=poly, score=0.4983996342021033, total=   0.5s\n",
      "[CV] C=1, gamma=0.0001, kernel=poly ..................................\n",
      "[CV]  C=1, gamma=0.0001, kernel=poly, score=0.49862637362637363, total=   0.5s\n",
      "[CV] C=1, gamma=0.0001, kernel=rbf ...................................\n",
      "[CV]  C=1, gamma=0.0001, kernel=rbf, score=0.4983996342021033, total=   0.8s\n",
      "[CV] C=1, gamma=0.0001, kernel=rbf ...................................\n",
      "[CV]  C=1, gamma=0.0001, kernel=rbf, score=0.4983996342021033, total=   0.8s\n",
      "[CV] C=1, gamma=0.0001, kernel=rbf ...................................\n",
      "[CV]  C=1, gamma=0.0001, kernel=rbf, score=0.49862637362637363, total=   0.8s\n",
      "[CV] C=1, gamma=0.0001, kernel=sigmoid ...............................\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  C=1, gamma=0.0001, kernel=sigmoid, score=0.4983996342021033, total=   0.7s\n",
      "[CV] C=1, gamma=0.0001, kernel=sigmoid ...............................\n",
      "[CV]  C=1, gamma=0.0001, kernel=sigmoid, score=0.4983996342021033, total=   0.8s\n",
      "[CV] C=1, gamma=0.0001, kernel=sigmoid ...............................\n",
      "[CV]  C=1, gamma=0.0001, kernel=sigmoid, score=0.49862637362637363, total=   0.7s\n",
      "[CV] C=1, gamma=0.0005, kernel=linear ................................\n",
      "[CV]  C=1, gamma=0.0005, kernel=linear, score=0.790580704160951, total=   0.1s\n",
      "[CV] C=1, gamma=0.0005, kernel=linear ................................\n",
      "[CV]  C=1, gamma=0.0005, kernel=linear, score=0.7988111568358482, total=   0.1s\n",
      "[CV] C=1, gamma=0.0005, kernel=linear ................................\n",
      "[CV]  C=1, gamma=0.0005, kernel=linear, score=0.7756410256410257, total=   0.1s\n",
      "[CV] C=1, gamma=0.0005, kernel=poly ..................................\n",
      "[CV]  C=1, gamma=0.0005, kernel=poly, score=0.4983996342021033, total=   0.5s\n",
      "[CV] C=1, gamma=0.0005, kernel=poly ..................................\n",
      "[CV]  C=1, gamma=0.0005, kernel=poly, score=0.4983996342021033, total=   0.5s\n",
      "[CV] C=1, gamma=0.0005, kernel=poly ..................................\n",
      "[CV]  C=1, gamma=0.0005, kernel=poly, score=0.49862637362637363, total=   0.5s\n",
      "[CV] C=1, gamma=0.0005, kernel=rbf ...................................\n",
      "[CV]  C=1, gamma=0.0005, kernel=rbf, score=0.4983996342021033, total=   0.8s\n",
      "[CV] C=1, gamma=0.0005, kernel=rbf ...................................\n",
      "[CV]  C=1, gamma=0.0005, kernel=rbf, score=0.4983996342021033, total=   0.8s\n",
      "[CV] C=1, gamma=0.0005, kernel=rbf ...................................\n",
      "[CV]  C=1, gamma=0.0005, kernel=rbf, score=0.49862637362637363, total=   0.8s\n",
      "[CV] C=1, gamma=0.0005, kernel=sigmoid ...............................\n",
      "[CV]  C=1, gamma=0.0005, kernel=sigmoid, score=0.4983996342021033, total=   0.7s\n",
      "[CV] C=1, gamma=0.0005, kernel=sigmoid ...............................\n",
      "[CV]  C=1, gamma=0.0005, kernel=sigmoid, score=0.4983996342021033, total=   0.7s\n",
      "[CV] C=1, gamma=0.0005, kernel=sigmoid ...............................\n",
      "[CV]  C=1, gamma=0.0005, kernel=sigmoid, score=0.49862637362637363, total=   0.7s\n",
      "[CV] C=1, gamma=0.001, kernel=linear .................................\n",
      "[CV]  C=1, gamma=0.001, kernel=linear, score=0.790580704160951, total=   0.1s\n",
      "[CV] C=1, gamma=0.001, kernel=linear .................................\n",
      "[CV]  C=1, gamma=0.001, kernel=linear, score=0.7988111568358482, total=   0.1s\n",
      "[CV] C=1, gamma=0.001, kernel=linear .................................\n",
      "[CV]  C=1, gamma=0.001, kernel=linear, score=0.7756410256410257, total=   0.1s\n",
      "[CV] C=1, gamma=0.001, kernel=poly ...................................\n",
      "[CV]  C=1, gamma=0.001, kernel=poly, score=0.4983996342021033, total=   0.5s\n",
      "[CV] C=1, gamma=0.001, kernel=poly ...................................\n",
      "[CV]  C=1, gamma=0.001, kernel=poly, score=0.4983996342021033, total=   0.5s\n",
      "[CV] C=1, gamma=0.001, kernel=poly ...................................\n",
      "[CV]  C=1, gamma=0.001, kernel=poly, score=0.49862637362637363, total=   0.5s\n",
      "[CV] C=1, gamma=0.001, kernel=rbf ....................................\n",
      "[CV]  C=1, gamma=0.001, kernel=rbf, score=0.4983996342021033, total=   0.8s\n",
      "[CV] C=1, gamma=0.001, kernel=rbf ....................................\n",
      "[CV]  C=1, gamma=0.001, kernel=rbf, score=0.4983996342021033, total=   0.8s\n",
      "[CV] C=1, gamma=0.001, kernel=rbf ....................................\n",
      "[CV]  C=1, gamma=0.001, kernel=rbf, score=0.49862637362637363, total=   0.8s\n",
      "[CV] C=1, gamma=0.001, kernel=sigmoid ................................\n",
      "[CV]  C=1, gamma=0.001, kernel=sigmoid, score=0.4983996342021033, total=   0.7s\n",
      "[CV] C=1, gamma=0.001, kernel=sigmoid ................................\n",
      "[CV]  C=1, gamma=0.001, kernel=sigmoid, score=0.4983996342021033, total=   0.7s\n",
      "[CV] C=1, gamma=0.001, kernel=sigmoid ................................\n",
      "[CV]  C=1, gamma=0.001, kernel=sigmoid, score=0.49862637362637363, total=   0.7s\n",
      "[CV] C=1, gamma=0.005, kernel=linear .................................\n",
      "[CV]  C=1, gamma=0.005, kernel=linear, score=0.790580704160951, total=   0.1s\n",
      "[CV] C=1, gamma=0.005, kernel=linear .................................\n",
      "[CV]  C=1, gamma=0.005, kernel=linear, score=0.7988111568358482, total=   0.1s\n",
      "[CV] C=1, gamma=0.005, kernel=linear .................................\n",
      "[CV]  C=1, gamma=0.005, kernel=linear, score=0.7756410256410257, total=   0.1s\n",
      "[CV] C=1, gamma=0.005, kernel=poly ...................................\n",
      "[CV]  C=1, gamma=0.005, kernel=poly, score=0.4983996342021033, total=   0.5s\n",
      "[CV] C=1, gamma=0.005, kernel=poly ...................................\n",
      "[CV]  C=1, gamma=0.005, kernel=poly, score=0.4983996342021033, total=   0.5s\n",
      "[CV] C=1, gamma=0.005, kernel=poly ...................................\n",
      "[CV]  C=1, gamma=0.005, kernel=poly, score=0.49862637362637363, total=   0.5s\n",
      "[CV] C=1, gamma=0.005, kernel=rbf ....................................\n",
      "[CV]  C=1, gamma=0.005, kernel=rbf, score=0.7375400091449474, total=   0.6s\n",
      "[CV] C=1, gamma=0.005, kernel=rbf ....................................\n",
      "[CV]  C=1, gamma=0.005, kernel=rbf, score=0.7338820301783264, total=   0.6s\n",
      "[CV] C=1, gamma=0.005, kernel=rbf ....................................\n",
      "[CV]  C=1, gamma=0.005, kernel=rbf, score=0.7348901098901099, total=   0.6s\n",
      "[CV] C=1, gamma=0.005, kernel=sigmoid ................................\n",
      "[CV]  C=1, gamma=0.005, kernel=sigmoid, score=0.7375400091449474, total=   0.7s\n",
      "[CV] C=1, gamma=0.005, kernel=sigmoid ................................\n",
      "[CV]  C=1, gamma=0.005, kernel=sigmoid, score=0.7338820301783264, total=   0.7s\n",
      "[CV] C=1, gamma=0.005, kernel=sigmoid ................................\n",
      "[CV]  C=1, gamma=0.005, kernel=sigmoid, score=0.7348901098901099, total=   0.7s\n",
      "[CV] C=5, gamma=0.0001, kernel=linear ................................\n",
      "[CV]  C=5, gamma=0.0001, kernel=linear, score=0.790580704160951, total=   0.1s\n",
      "[CV] C=5, gamma=0.0001, kernel=linear ................................\n",
      "[CV]  C=5, gamma=0.0001, kernel=linear, score=0.7937814357567444, total=   0.1s\n",
      "[CV] C=5, gamma=0.0001, kernel=linear ................................\n",
      "[CV]  C=5, gamma=0.0001, kernel=linear, score=0.7673992673992674, total=   0.1s\n",
      "[CV] C=5, gamma=0.0001, kernel=poly ..................................\n",
      "[CV]  C=5, gamma=0.0001, kernel=poly, score=0.4983996342021033, total=   0.5s\n",
      "[CV] C=5, gamma=0.0001, kernel=poly ..................................\n",
      "[CV]  C=5, gamma=0.0001, kernel=poly, score=0.4983996342021033, total=   0.5s\n",
      "[CV] C=5, gamma=0.0001, kernel=poly ..................................\n",
      "[CV]  C=5, gamma=0.0001, kernel=poly, score=0.49862637362637363, total=   0.5s\n",
      "[CV] C=5, gamma=0.0001, kernel=rbf ...................................\n",
      "[CV]  C=5, gamma=0.0001, kernel=rbf, score=0.4983996342021033, total=   0.8s\n",
      "[CV] C=5, gamma=0.0001, kernel=rbf ...................................\n",
      "[CV]  C=5, gamma=0.0001, kernel=rbf, score=0.4983996342021033, total=   0.8s\n",
      "[CV] C=5, gamma=0.0001, kernel=rbf ...................................\n",
      "[CV]  C=5, gamma=0.0001, kernel=rbf, score=0.49862637362637363, total=   0.8s\n",
      "[CV] C=5, gamma=0.0001, kernel=sigmoid ...............................\n",
      "[CV]  C=5, gamma=0.0001, kernel=sigmoid, score=0.4983996342021033, total=   0.7s\n",
      "[CV] C=5, gamma=0.0001, kernel=sigmoid ...............................\n",
      "[CV]  C=5, gamma=0.0001, kernel=sigmoid, score=0.4983996342021033, total=   0.7s\n",
      "[CV] C=5, gamma=0.0001, kernel=sigmoid ...............................\n",
      "[CV]  C=5, gamma=0.0001, kernel=sigmoid, score=0.49862637362637363, total=   0.7s\n",
      "[CV] C=5, gamma=0.0005, kernel=linear ................................\n",
      "[CV]  C=5, gamma=0.0005, kernel=linear, score=0.790580704160951, total=   0.1s\n",
      "[CV] C=5, gamma=0.0005, kernel=linear ................................\n",
      "[CV]  C=5, gamma=0.0005, kernel=linear, score=0.7937814357567444, total=   0.1s\n",
      "[CV] C=5, gamma=0.0005, kernel=linear ................................\n",
      "[CV]  C=5, gamma=0.0005, kernel=linear, score=0.7673992673992674, total=   0.1s\n",
      "[CV] C=5, gamma=0.0005, kernel=poly ..................................\n",
      "[CV]  C=5, gamma=0.0005, kernel=poly, score=0.4983996342021033, total=   0.5s\n",
      "[CV] C=5, gamma=0.0005, kernel=poly ..................................\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  C=5, gamma=0.0005, kernel=poly, score=0.4983996342021033, total=   0.5s\n",
      "[CV] C=5, gamma=0.0005, kernel=poly ..................................\n",
      "[CV]  C=5, gamma=0.0005, kernel=poly, score=0.49862637362637363, total=   0.5s\n",
      "[CV] C=5, gamma=0.0005, kernel=rbf ...................................\n",
      "[CV]  C=5, gamma=0.0005, kernel=rbf, score=0.7375400091449474, total=   0.8s\n",
      "[CV] C=5, gamma=0.0005, kernel=rbf ...................................\n",
      "[CV]  C=5, gamma=0.0005, kernel=rbf, score=0.7338820301783264, total=   0.8s\n",
      "[CV] C=5, gamma=0.0005, kernel=rbf ...................................\n",
      "[CV]  C=5, gamma=0.0005, kernel=rbf, score=0.7348901098901099, total=   0.9s\n",
      "[CV] C=5, gamma=0.0005, kernel=sigmoid ...............................\n",
      "[CV]  C=5, gamma=0.0005, kernel=sigmoid, score=0.4983996342021033, total=   0.7s\n",
      "[CV] C=5, gamma=0.0005, kernel=sigmoid ...............................\n",
      "[CV]  C=5, gamma=0.0005, kernel=sigmoid, score=0.49885688157293095, total=   0.7s\n",
      "[CV] C=5, gamma=0.0005, kernel=sigmoid ...............................\n",
      "[CV]  C=5, gamma=0.0005, kernel=sigmoid, score=0.49862637362637363, total=   0.7s\n",
      "[CV] C=5, gamma=0.001, kernel=linear .................................\n",
      "[CV]  C=5, gamma=0.001, kernel=linear, score=0.790580704160951, total=   0.1s\n",
      "[CV] C=5, gamma=0.001, kernel=linear .................................\n",
      "[CV]  C=5, gamma=0.001, kernel=linear, score=0.7937814357567444, total=   0.1s\n",
      "[CV] C=5, gamma=0.001, kernel=linear .................................\n",
      "[CV]  C=5, gamma=0.001, kernel=linear, score=0.7673992673992674, total=   0.1s\n",
      "[CV] C=5, gamma=0.001, kernel=poly ...................................\n",
      "[CV]  C=5, gamma=0.001, kernel=poly, score=0.4983996342021033, total=   0.5s\n",
      "[CV] C=5, gamma=0.001, kernel=poly ...................................\n",
      "[CV]  C=5, gamma=0.001, kernel=poly, score=0.4983996342021033, total=   0.5s\n",
      "[CV] C=5, gamma=0.001, kernel=poly ...................................\n",
      "[CV]  C=5, gamma=0.001, kernel=poly, score=0.49862637362637363, total=   0.5s\n",
      "[CV] C=5, gamma=0.001, kernel=rbf ....................................\n",
      "[CV]  C=5, gamma=0.001, kernel=rbf, score=0.7375400091449474, total=   0.6s\n",
      "[CV] C=5, gamma=0.001, kernel=rbf ....................................\n",
      "[CV]  C=5, gamma=0.001, kernel=rbf, score=0.7338820301783264, total=   0.6s\n",
      "[CV] C=5, gamma=0.001, kernel=rbf ....................................\n",
      "[CV]  C=5, gamma=0.001, kernel=rbf, score=0.7348901098901099, total=   0.6s\n",
      "[CV] C=5, gamma=0.001, kernel=sigmoid ................................\n",
      "[CV]  C=5, gamma=0.001, kernel=sigmoid, score=0.7375400091449474, total=   0.7s\n",
      "[CV] C=5, gamma=0.001, kernel=sigmoid ................................\n",
      "[CV]  C=5, gamma=0.001, kernel=sigmoid, score=0.7338820301783264, total=   0.7s\n",
      "[CV] C=5, gamma=0.001, kernel=sigmoid ................................\n",
      "[CV]  C=5, gamma=0.001, kernel=sigmoid, score=0.7348901098901099, total=   0.8s\n",
      "[CV] C=5, gamma=0.005, kernel=linear .................................\n",
      "[CV]  C=5, gamma=0.005, kernel=linear, score=0.790580704160951, total=   0.1s\n",
      "[CV] C=5, gamma=0.005, kernel=linear .................................\n",
      "[CV]  C=5, gamma=0.005, kernel=linear, score=0.7937814357567444, total=   0.1s\n",
      "[CV] C=5, gamma=0.005, kernel=linear .................................\n",
      "[CV]  C=5, gamma=0.005, kernel=linear, score=0.7673992673992674, total=   0.1s\n",
      "[CV] C=5, gamma=0.005, kernel=poly ...................................\n",
      "[CV]  C=5, gamma=0.005, kernel=poly, score=0.4983996342021033, total=   0.5s\n",
      "[CV] C=5, gamma=0.005, kernel=poly ...................................\n",
      "[CV]  C=5, gamma=0.005, kernel=poly, score=0.4983996342021033, total=   0.5s\n",
      "[CV] C=5, gamma=0.005, kernel=poly ...................................\n",
      "[CV]  C=5, gamma=0.005, kernel=poly, score=0.49862637362637363, total=   0.5s\n",
      "[CV] C=5, gamma=0.005, kernel=rbf ....................................\n",
      "[CV]  C=5, gamma=0.005, kernel=rbf, score=0.7695473251028807, total=   0.4s\n",
      "[CV] C=5, gamma=0.005, kernel=rbf ....................................\n",
      "[CV]  C=5, gamma=0.005, kernel=rbf, score=0.7521719250114312, total=   0.4s\n",
      "[CV] C=5, gamma=0.005, kernel=rbf ....................................\n",
      "[CV]  C=5, gamma=0.005, kernel=rbf, score=0.760989010989011, total=   0.4s\n",
      "[CV] C=5, gamma=0.005, kernel=sigmoid ................................\n",
      "[CV]  C=5, gamma=0.005, kernel=sigmoid, score=0.7379972565157751, total=   0.3s\n",
      "[CV] C=5, gamma=0.005, kernel=sigmoid ................................\n",
      "[CV]  C=5, gamma=0.005, kernel=sigmoid, score=0.7338820301783264, total=   0.3s\n",
      "[CV] C=5, gamma=0.005, kernel=sigmoid ................................\n",
      "[CV]  C=5, gamma=0.005, kernel=sigmoid, score=0.7358058608058609, total=   0.3s\n",
      "[CV] C=10, gamma=0.0001, kernel=linear ...............................\n",
      "[CV]  C=10, gamma=0.0001, kernel=linear, score=0.788294467306813, total=   0.1s\n",
      "[CV] C=10, gamma=0.0001, kernel=linear ...............................\n",
      "[CV]  C=10, gamma=0.0001, kernel=linear, score=0.7942386831275721, total=   0.1s\n",
      "[CV] C=10, gamma=0.0001, kernel=linear ...............................\n",
      "[CV]  C=10, gamma=0.0001, kernel=linear, score=0.7673992673992674, total=   0.1s\n",
      "[CV] C=10, gamma=0.0001, kernel=poly .................................\n",
      "[CV]  C=10, gamma=0.0001, kernel=poly, score=0.4983996342021033, total=   0.5s\n",
      "[CV] C=10, gamma=0.0001, kernel=poly .................................\n",
      "[CV]  C=10, gamma=0.0001, kernel=poly, score=0.4983996342021033, total=   0.5s\n",
      "[CV] C=10, gamma=0.0001, kernel=poly .................................\n",
      "[CV]  C=10, gamma=0.0001, kernel=poly, score=0.49862637362637363, total=   0.5s\n",
      "[CV] C=10, gamma=0.0001, kernel=rbf ..................................\n",
      "[CV]  C=10, gamma=0.0001, kernel=rbf, score=0.4983996342021033, total=   0.8s\n",
      "[CV] C=10, gamma=0.0001, kernel=rbf ..................................\n",
      "[CV]  C=10, gamma=0.0001, kernel=rbf, score=0.4983996342021033, total=   0.8s\n",
      "[CV] C=10, gamma=0.0001, kernel=rbf ..................................\n",
      "[CV]  C=10, gamma=0.0001, kernel=rbf, score=0.49862637362637363, total=   0.8s\n",
      "[CV] C=10, gamma=0.0001, kernel=sigmoid ..............................\n",
      "[CV]  C=10, gamma=0.0001, kernel=sigmoid, score=0.4983996342021033, total=   0.7s\n",
      "[CV] C=10, gamma=0.0001, kernel=sigmoid ..............................\n",
      "[CV]  C=10, gamma=0.0001, kernel=sigmoid, score=0.4983996342021033, total=   0.7s\n",
      "[CV] C=10, gamma=0.0001, kernel=sigmoid ..............................\n",
      "[CV]  C=10, gamma=0.0001, kernel=sigmoid, score=0.49862637362637363, total=   0.7s\n",
      "[CV] C=10, gamma=0.0005, kernel=linear ...............................\n",
      "[CV]  C=10, gamma=0.0005, kernel=linear, score=0.788294467306813, total=   0.1s\n",
      "[CV] C=10, gamma=0.0005, kernel=linear ...............................\n",
      "[CV]  C=10, gamma=0.0005, kernel=linear, score=0.7942386831275721, total=   0.1s\n",
      "[CV] C=10, gamma=0.0005, kernel=linear ...............................\n",
      "[CV]  C=10, gamma=0.0005, kernel=linear, score=0.7673992673992674, total=   0.1s\n",
      "[CV] C=10, gamma=0.0005, kernel=poly .................................\n",
      "[CV]  C=10, gamma=0.0005, kernel=poly, score=0.4983996342021033, total=   0.5s\n",
      "[CV] C=10, gamma=0.0005, kernel=poly .................................\n",
      "[CV]  C=10, gamma=0.0005, kernel=poly, score=0.4983996342021033, total=   0.5s\n",
      "[CV] C=10, gamma=0.0005, kernel=poly .................................\n",
      "[CV]  C=10, gamma=0.0005, kernel=poly, score=0.49862637362637363, total=   0.5s\n",
      "[CV] C=10, gamma=0.0005, kernel=rbf ..................................\n",
      "[CV]  C=10, gamma=0.0005, kernel=rbf, score=0.7375400091449474, total=   0.6s\n",
      "[CV] C=10, gamma=0.0005, kernel=rbf ..................................\n",
      "[CV]  C=10, gamma=0.0005, kernel=rbf, score=0.7338820301783264, total=   0.6s\n",
      "[CV] C=10, gamma=0.0005, kernel=rbf ..................................\n",
      "[CV]  C=10, gamma=0.0005, kernel=rbf, score=0.7348901098901099, total=   0.6s\n",
      "[CV] C=10, gamma=0.0005, kernel=sigmoid ..............................\n",
      "[CV]  C=10, gamma=0.0005, kernel=sigmoid, score=0.7375400091449474, total=   0.7s\n",
      "[CV] C=10, gamma=0.0005, kernel=sigmoid ..............................\n",
      "[CV]  C=10, gamma=0.0005, kernel=sigmoid, score=0.7338820301783264, total=   0.7s\n",
      "[CV] C=10, gamma=0.0005, kernel=sigmoid ..............................\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  C=10, gamma=0.0005, kernel=sigmoid, score=0.7348901098901099, total=   0.7s\n",
      "[CV] C=10, gamma=0.001, kernel=linear ................................\n",
      "[CV]  C=10, gamma=0.001, kernel=linear, score=0.788294467306813, total=   0.1s\n",
      "[CV] C=10, gamma=0.001, kernel=linear ................................\n",
      "[CV]  C=10, gamma=0.001, kernel=linear, score=0.7942386831275721, total=   0.1s\n",
      "[CV] C=10, gamma=0.001, kernel=linear ................................\n",
      "[CV]  C=10, gamma=0.001, kernel=linear, score=0.7673992673992674, total=   0.1s\n",
      "[CV] C=10, gamma=0.001, kernel=poly ..................................\n",
      "[CV]  C=10, gamma=0.001, kernel=poly, score=0.4983996342021033, total=   0.5s\n",
      "[CV] C=10, gamma=0.001, kernel=poly ..................................\n",
      "[CV]  C=10, gamma=0.001, kernel=poly, score=0.4983996342021033, total=   0.5s\n",
      "[CV] C=10, gamma=0.001, kernel=poly ..................................\n",
      "[CV]  C=10, gamma=0.001, kernel=poly, score=0.49862637362637363, total=   0.5s\n",
      "[CV] C=10, gamma=0.001, kernel=rbf ...................................\n",
      "[CV]  C=10, gamma=0.001, kernel=rbf, score=0.7375400091449474, total=   0.4s\n",
      "[CV] C=10, gamma=0.001, kernel=rbf ...................................\n",
      "[CV]  C=10, gamma=0.001, kernel=rbf, score=0.7338820301783264, total=   0.4s\n",
      "[CV] C=10, gamma=0.001, kernel=rbf ...................................\n",
      "[CV]  C=10, gamma=0.001, kernel=rbf, score=0.7348901098901099, total=   0.4s\n",
      "[CV] C=10, gamma=0.001, kernel=sigmoid ...............................\n",
      "[CV]  C=10, gamma=0.001, kernel=sigmoid, score=0.7375400091449474, total=   0.5s\n",
      "[CV] C=10, gamma=0.001, kernel=sigmoid ...............................\n",
      "[CV]  C=10, gamma=0.001, kernel=sigmoid, score=0.7338820301783264, total=   0.5s\n",
      "[CV] C=10, gamma=0.001, kernel=sigmoid ...............................\n",
      "[CV]  C=10, gamma=0.001, kernel=sigmoid, score=0.7348901098901099, total=   0.5s\n",
      "[CV] C=10, gamma=0.005, kernel=linear ................................\n",
      "[CV]  C=10, gamma=0.005, kernel=linear, score=0.788294467306813, total=   0.1s\n",
      "[CV] C=10, gamma=0.005, kernel=linear ................................\n",
      "[CV]  C=10, gamma=0.005, kernel=linear, score=0.7942386831275721, total=   0.1s\n",
      "[CV] C=10, gamma=0.005, kernel=linear ................................\n",
      "[CV]  C=10, gamma=0.005, kernel=linear, score=0.7673992673992674, total=   0.1s\n",
      "[CV] C=10, gamma=0.005, kernel=poly ..................................\n",
      "[CV]  C=10, gamma=0.005, kernel=poly, score=0.4983996342021033, total=   0.5s\n",
      "[CV] C=10, gamma=0.005, kernel=poly ..................................\n",
      "[CV]  C=10, gamma=0.005, kernel=poly, score=0.4983996342021033, total=   0.5s\n",
      "[CV] C=10, gamma=0.005, kernel=poly ..................................\n",
      "[CV]  C=10, gamma=0.005, kernel=poly, score=0.49862637362637363, total=   0.5s\n",
      "[CV] C=10, gamma=0.005, kernel=rbf ...................................\n",
      "[CV]  C=10, gamma=0.005, kernel=rbf, score=0.7832647462277091, total=   0.4s\n",
      "[CV] C=10, gamma=0.005, kernel=rbf ...................................\n",
      "[CV]  C=10, gamma=0.005, kernel=rbf, score=0.7722908093278463, total=   0.4s\n",
      "[CV] C=10, gamma=0.005, kernel=rbf ...................................\n",
      "[CV]  C=10, gamma=0.005, kernel=rbf, score=0.7751831501831502, total=   0.4s\n",
      "[CV] C=10, gamma=0.005, kernel=sigmoid ...............................\n",
      "[CV]  C=10, gamma=0.005, kernel=sigmoid, score=0.7690900777320531, total=   0.3s\n",
      "[CV] C=10, gamma=0.005, kernel=sigmoid ...............................\n",
      "[CV]  C=10, gamma=0.005, kernel=sigmoid, score=0.7521719250114312, total=   0.3s\n",
      "[CV] C=10, gamma=0.005, kernel=sigmoid ...............................\n",
      "[CV]  C=10, gamma=0.005, kernel=sigmoid, score=0.7614468864468864, total=   0.3s\n",
      "[CV] C=50, gamma=0.0001, kernel=linear ...............................\n",
      "[CV]  C=50, gamma=0.0001, kernel=linear, score=0.7901234567901234, total=   0.3s\n",
      "[CV] C=50, gamma=0.0001, kernel=linear ...............................\n",
      "[CV]  C=50, gamma=0.0001, kernel=linear, score=0.7942386831275721, total=   0.2s\n",
      "[CV] C=50, gamma=0.0001, kernel=linear ...............................\n",
      "[CV]  C=50, gamma=0.0001, kernel=linear, score=0.7692307692307693, total=   0.2s\n",
      "[CV] C=50, gamma=0.0001, kernel=poly .................................\n",
      "[CV]  C=50, gamma=0.0001, kernel=poly, score=0.4983996342021033, total=   0.5s\n",
      "[CV] C=50, gamma=0.0001, kernel=poly .................................\n",
      "[CV]  C=50, gamma=0.0001, kernel=poly, score=0.4983996342021033, total=   0.5s\n",
      "[CV] C=50, gamma=0.0001, kernel=poly .................................\n",
      "[CV]  C=50, gamma=0.0001, kernel=poly, score=0.49862637362637363, total=   0.5s\n",
      "[CV] C=50, gamma=0.0001, kernel=rbf ..................................\n",
      "[CV]  C=50, gamma=0.0001, kernel=rbf, score=0.7375400091449474, total=   0.6s\n",
      "[CV] C=50, gamma=0.0001, kernel=rbf ..................................\n",
      "[CV]  C=50, gamma=0.0001, kernel=rbf, score=0.7338820301783264, total=   0.6s\n",
      "[CV] C=50, gamma=0.0001, kernel=rbf ..................................\n",
      "[CV]  C=50, gamma=0.0001, kernel=rbf, score=0.7348901098901099, total=   0.6s\n",
      "[CV] C=50, gamma=0.0001, kernel=sigmoid ..............................\n",
      "[CV]  C=50, gamma=0.0001, kernel=sigmoid, score=0.7375400091449474, total=   0.8s\n",
      "[CV] C=50, gamma=0.0001, kernel=sigmoid ..............................\n",
      "[CV]  C=50, gamma=0.0001, kernel=sigmoid, score=0.7338820301783264, total=   0.8s\n",
      "[CV] C=50, gamma=0.0001, kernel=sigmoid ..............................\n",
      "[CV]  C=50, gamma=0.0001, kernel=sigmoid, score=0.7348901098901099, total=   0.8s\n",
      "[CV] C=50, gamma=0.0005, kernel=linear ...............................\n",
      "[CV]  C=50, gamma=0.0005, kernel=linear, score=0.7901234567901234, total=   0.3s\n",
      "[CV] C=50, gamma=0.0005, kernel=linear ...............................\n",
      "[CV]  C=50, gamma=0.0005, kernel=linear, score=0.7942386831275721, total=   0.2s\n",
      "[CV] C=50, gamma=0.0005, kernel=linear ...............................\n",
      "[CV]  C=50, gamma=0.0005, kernel=linear, score=0.7692307692307693, total=   0.2s\n",
      "[CV] C=50, gamma=0.0005, kernel=poly .................................\n",
      "[CV]  C=50, gamma=0.0005, kernel=poly, score=0.4983996342021033, total=   0.5s\n",
      "[CV] C=50, gamma=0.0005, kernel=poly .................................\n",
      "[CV]  C=50, gamma=0.0005, kernel=poly, score=0.4983996342021033, total=   0.5s\n",
      "[CV] C=50, gamma=0.0005, kernel=poly .................................\n",
      "[CV]  C=50, gamma=0.0005, kernel=poly, score=0.49862637362637363, total=   0.5s\n",
      "[CV] C=50, gamma=0.0005, kernel=rbf ..................................\n",
      "[CV]  C=50, gamma=0.0005, kernel=rbf, score=0.7690900777320531, total=   0.3s\n",
      "[CV] C=50, gamma=0.0005, kernel=rbf ..................................\n",
      "[CV]  C=50, gamma=0.0005, kernel=rbf, score=0.7521719250114312, total=   0.3s\n",
      "[CV] C=50, gamma=0.0005, kernel=rbf ..................................\n",
      "[CV]  C=50, gamma=0.0005, kernel=rbf, score=0.7614468864468864, total=   0.3s\n",
      "[CV] C=50, gamma=0.0005, kernel=sigmoid ..............................\n",
      "[CV]  C=50, gamma=0.0005, kernel=sigmoid, score=0.7379972565157751, total=   0.4s\n",
      "[CV] C=50, gamma=0.0005, kernel=sigmoid ..............................\n",
      "[CV]  C=50, gamma=0.0005, kernel=sigmoid, score=0.7338820301783264, total=   0.3s\n",
      "[CV] C=50, gamma=0.0005, kernel=sigmoid ..............................\n",
      "[CV]  C=50, gamma=0.0005, kernel=sigmoid, score=0.7358058608058609, total=   0.3s\n",
      "[CV] C=50, gamma=0.001, kernel=linear ................................\n",
      "[CV]  C=50, gamma=0.001, kernel=linear, score=0.7901234567901234, total=   0.2s\n",
      "[CV] C=50, gamma=0.001, kernel=linear ................................\n",
      "[CV]  C=50, gamma=0.001, kernel=linear, score=0.7942386831275721, total=   0.2s\n",
      "[CV] C=50, gamma=0.001, kernel=linear ................................\n",
      "[CV]  C=50, gamma=0.001, kernel=linear, score=0.7692307692307693, total=   0.2s\n",
      "[CV] C=50, gamma=0.001, kernel=poly ..................................\n",
      "[CV]  C=50, gamma=0.001, kernel=poly, score=0.4983996342021033, total=   0.5s\n",
      "[CV] C=50, gamma=0.001, kernel=poly ..................................\n",
      "[CV]  C=50, gamma=0.001, kernel=poly, score=0.4983996342021033, total=   0.5s\n",
      "[CV] C=50, gamma=0.001, kernel=poly ..................................\n",
      "[CV]  C=50, gamma=0.001, kernel=poly, score=0.49862637362637363, total=   0.5s\n",
      "[CV] C=50, gamma=0.001, kernel=rbf ...................................\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  C=50, gamma=0.001, kernel=rbf, score=0.7832647462277091, total=   0.4s\n",
      "[CV] C=50, gamma=0.001, kernel=rbf ...................................\n",
      "[CV]  C=50, gamma=0.001, kernel=rbf, score=0.772748056698674, total=   0.4s\n",
      "[CV] C=50, gamma=0.001, kernel=rbf ...................................\n",
      "[CV]  C=50, gamma=0.001, kernel=rbf, score=0.7751831501831502, total=   0.3s\n",
      "[CV] C=50, gamma=0.001, kernel=sigmoid ...............................\n",
      "[CV]  C=50, gamma=0.001, kernel=sigmoid, score=0.7690900777320531, total=   0.3s\n",
      "[CV] C=50, gamma=0.001, kernel=sigmoid ...............................\n",
      "[CV]  C=50, gamma=0.001, kernel=sigmoid, score=0.7521719250114312, total=   0.3s\n",
      "[CV] C=50, gamma=0.001, kernel=sigmoid ...............................\n",
      "[CV]  C=50, gamma=0.001, kernel=sigmoid, score=0.7614468864468864, total=   0.3s\n",
      "[CV] C=50, gamma=0.005, kernel=linear ................................\n",
      "[CV]  C=50, gamma=0.005, kernel=linear, score=0.7901234567901234, total=   0.2s\n",
      "[CV] C=50, gamma=0.005, kernel=linear ................................\n",
      "[CV]  C=50, gamma=0.005, kernel=linear, score=0.7942386831275721, total=   0.2s\n",
      "[CV] C=50, gamma=0.005, kernel=linear ................................\n",
      "[CV]  C=50, gamma=0.005, kernel=linear, score=0.7692307692307693, total=   0.3s\n",
      "[CV] C=50, gamma=0.005, kernel=poly ..................................\n",
      "[CV]  C=50, gamma=0.005, kernel=poly, score=0.4983996342021033, total=   0.6s\n",
      "[CV] C=50, gamma=0.005, kernel=poly ..................................\n",
      "[CV]  C=50, gamma=0.005, kernel=poly, score=0.4983996342021033, total=   0.6s\n",
      "[CV] C=50, gamma=0.005, kernel=poly ..................................\n",
      "[CV]  C=50, gamma=0.005, kernel=poly, score=0.49862637362637363, total=   0.5s\n",
      "[CV] C=50, gamma=0.005, kernel=rbf ...................................\n",
      "[CV]  C=50, gamma=0.005, kernel=rbf, score=0.7873799725651578, total=   0.4s\n",
      "[CV] C=50, gamma=0.005, kernel=rbf ...................................\n",
      "[CV]  C=50, gamma=0.005, kernel=rbf, score=0.7910379515317787, total=   0.4s\n",
      "[CV] C=50, gamma=0.005, kernel=rbf ...................................\n",
      "[CV]  C=50, gamma=0.005, kernel=rbf, score=0.7742673992673993, total=   0.4s\n",
      "[CV] C=50, gamma=0.005, kernel=sigmoid ...............................\n",
      "[CV]  C=50, gamma=0.005, kernel=sigmoid, score=0.7850937357110197, total=   0.2s\n",
      "[CV] C=50, gamma=0.005, kernel=sigmoid ...............................\n",
      "[CV]  C=50, gamma=0.005, kernel=sigmoid, score=0.7887517146776406, total=   0.3s\n",
      "[CV] C=50, gamma=0.005, kernel=sigmoid ...............................\n",
      "[CV]  C=50, gamma=0.005, kernel=sigmoid, score=0.7756410256410257, total=   0.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done 240 out of 240 | elapsed:  3.4min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv='warn', error_score='raise-deprecating',\n",
       "       estimator=SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
       "  decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
       "  kernel='linear', max_iter=-1, probability=False, random_state=None,\n",
       "  shrinking=True, tol=0.001, verbose=False),\n",
       "       fit_params=None, iid='warn', n_jobs=None,\n",
       "       param_grid={'C': [0.1, 1, 5, 10, 50], 'kernel': ['linear', 'poly', 'rbf', 'sigmoid'], 'gamma': [0.0001, 0.0005, 0.001, 0.005]},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
       "       scoring=None, verbose=3)"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fit svm model using grid search estimator\n",
    "grid_svm.fit(X_train_scaled_mms, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'C': 1, 'gamma': 0.0001, 'kernel': 'linear'}\n"
     ]
    }
   ],
   "source": [
    "# List the best parameters for this dataset\n",
    "print(grid_svm.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Data Score: 0.786062824031717\n",
      "Testing Data Score: 0.7964318389752973\n"
     ]
    }
   ],
   "source": [
    "# Scores for train and test data after hyperparameter tuning of the model\n",
    "print(f\"Training Data Score: {grid_svm.score(X_train_scaled_mms, y_train)}\")\n",
    "print(f\"Testing Data Score: {grid_svm.score(X_test_scaled_mms, y_test)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.71      0.33      0.45       510\n",
      "           1       0.59      0.88      0.71       587\n",
      "           2       0.98      0.97      0.97      1089\n",
      "\n",
      "   micro avg       0.80      0.80      0.80      2186\n",
      "   macro avg       0.76      0.73      0.71      2186\n",
      "weighted avg       0.81      0.80      0.78      2186\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Calculate classification report\n",
    "print(classification_report(\n",
    "    y_test, grid_svm.predict(X_test_scaled_mms), target_names=[\"0\", \"1\", \"2\"]\n",
    "))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>target_test</th>\n",
       "      <th>target_predicted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>FALSE POSITIVE</td>\n",
       "      <td>FALSE POSITIVE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>FALSE POSITIVE</td>\n",
       "      <td>FALSE POSITIVE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>CONFIRMED</td>\n",
       "      <td>CONFIRMED</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>CANDIDATE</td>\n",
       "      <td>CONFIRMED</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>FALSE POSITIVE</td>\n",
       "      <td>FALSE POSITIVE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>CONFIRMED</td>\n",
       "      <td>CONFIRMED</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>CANDIDATE</td>\n",
       "      <td>CONFIRMED</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>FALSE POSITIVE</td>\n",
       "      <td>FALSE POSITIVE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>FALSE POSITIVE</td>\n",
       "      <td>FALSE POSITIVE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>FALSE POSITIVE</td>\n",
       "      <td>CANDIDATE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>CONFIRMED</td>\n",
       "      <td>CONFIRMED</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>CANDIDATE</td>\n",
       "      <td>CONFIRMED</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>FALSE POSITIVE</td>\n",
       "      <td>FALSE POSITIVE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>CONFIRMED</td>\n",
       "      <td>CONFIRMED</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>CANDIDATE</td>\n",
       "      <td>CONFIRMED</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>CANDIDATE</td>\n",
       "      <td>CONFIRMED</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       target_test target_predicted\n",
       "0   FALSE POSITIVE   FALSE POSITIVE\n",
       "1   FALSE POSITIVE   FALSE POSITIVE\n",
       "2        CONFIRMED        CONFIRMED\n",
       "3        CANDIDATE        CONFIRMED\n",
       "4   FALSE POSITIVE   FALSE POSITIVE\n",
       "5        CONFIRMED        CONFIRMED\n",
       "6        CANDIDATE        CONFIRMED\n",
       "7   FALSE POSITIVE   FALSE POSITIVE\n",
       "8   FALSE POSITIVE   FALSE POSITIVE\n",
       "9   FALSE POSITIVE        CANDIDATE\n",
       "10       CONFIRMED        CONFIRMED\n",
       "11       CANDIDATE        CONFIRMED\n",
       "12  FALSE POSITIVE   FALSE POSITIVE\n",
       "13       CONFIRMED        CONFIRMED\n",
       "14       CANDIDATE        CONFIRMED\n",
       "15       CANDIDATE        CONFIRMED"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# DataFrame for test and predicted data\n",
    "target_pred_test_svm = pd.DataFrame({\n",
    "    \"target_test\": target_encoder.inverse_transform(y_test),\n",
    "    \"target_predicted\": target_encoder.inverse_transform(grid_svm.predict(X_test_scaled_mms))\n",
    "})\n",
    "\n",
    "# Preview \"target_pred_test_svm\"\n",
    "target_pred_test_svm.head(16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['../models/kepler_svm_model.h5']"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Save model as .h5 file\n",
    "joblib.dump(grid_svm.best_estimator_, '../models/kepler_svm_model.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color=\"navy\">KNN Model</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "k: 1, Train/Test Score: 1.000/0.750\n",
      "k: 3, Train/Test Score: 0.871/0.769\n",
      "k: 5, Train/Test Score: 0.850/0.787\n",
      "k: 7, Train/Test Score: 0.834/0.776\n",
      "k: 9, Train/Test Score: 0.826/0.775\n",
      "k: 11, Train/Test Score: 0.812/0.779\n",
      "k: 13, Train/Test Score: 0.811/0.783\n",
      "k: 15, Train/Test Score: 0.812/0.778\n",
      "k: 17, Train/Test Score: 0.807/0.775\n",
      "k: 19, Train/Test Score: 0.801/0.777\n",
      "k: 21, Train/Test Score: 0.800/0.780\n",
      "k: 23, Train/Test Score: 0.798/0.779\n",
      "k: 25, Train/Test Score: 0.799/0.784\n",
      "k: 27, Train/Test Score: 0.798/0.785\n",
      "k: 29, Train/Test Score: 0.797/0.783\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Loop through different k values to see which has the highest accuracy\n",
    "# Note: We only use odd numbers because we don't want any ties\n",
    "train_scores = []\n",
    "test_scores = []\n",
    "for k in range(1, 30, 2):\n",
    "    # Create KNN classifier\n",
    "    knn = KNeighborsClassifier(n_neighbors=k)\n",
    "    # Fit model with train data\n",
    "    knn.fit(X_train_scaled_mms, y_train)\n",
    "    # Scores for train and test data for each k\n",
    "    train_score = knn.score(X_train_scaled_mms, y_train)\n",
    "    test_score = knn.score(X_test_scaled_mms, y_test)\n",
    "    train_scores.append(train_score)\n",
    "    test_scores.append(test_score)\n",
    "    print(f\"k: {k}, Train/Test Score: {train_score:.3f}/{test_score:.3f}\")\n",
    "\n",
    " \n",
    "    \n",
    "    \n",
    "plt.plot(range(1, 30, 2), train_scores, marker='o')\n",
    "plt.plot(range(1, 30, 2), test_scores, marker=\"x\")\n",
    "plt.xlabel(\"k neighbors\")\n",
    "plt.ylabel(\"Testing accuracy Score\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
       "           metric_params=None, n_jobs=None, n_neighbors=25, p=2,\n",
       "           weights='uniform')"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Note that k: 25 seems to be the best choice for this dataset\n",
    "knn = KNeighborsClassifier(n_neighbors=25)\n",
    "knn.fit(X_train_scaled_mms, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Data Score: 0.7985666361695639\n",
      "Testing Data Score: 0.7840805123513266\n"
     ]
    }
   ],
   "source": [
    "# Scores for train and test data\n",
    "print(f\"Training Data Score: {knn.score(X_train_scaled_mms, y_train)}\")\n",
    "print(f\"Testing Data Score: {knn.score(X_test_scaled_mms, y_test)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up tuning parameters\n",
    "param_grid_knn = {'weights': [\"uniform\", \"distance\"],\n",
    "                  'algorithm': [\"ball_tree\", \"kd_tree\", \"brute\"],\n",
    "                  'p': [1, 2]\n",
    "                 }\n",
    "              \n",
    "grid_knn = GridSearchCV(knn, param_grid_knn, verbose=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kouda\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py:2053: FutureWarning: You should specify a value for 'cv' instead of relying on the default value. The default value will change from 3 to 5 in version 0.22.\n",
      "  warnings.warn(CV_WARNING, FutureWarning)\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 12 candidates, totalling 36 fits\n",
      "[CV] algorithm=ball_tree, p=1, weights=uniform .......................\n",
      "[CV]  algorithm=ball_tree, p=1, weights=uniform, score=0.7850937357110197, total=   0.1s\n",
      "[CV] algorithm=ball_tree, p=1, weights=uniform .......................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.4s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  algorithm=ball_tree, p=1, weights=uniform, score=0.7745770461819844, total=   0.1s\n",
      "[CV] algorithm=ball_tree, p=1, weights=uniform .......................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    0.8s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  algorithm=ball_tree, p=1, weights=uniform, score=0.7568681318681318, total=   0.1s\n",
      "[CV] algorithm=ball_tree, p=1, weights=distance ......................\n",
      "[CV]  algorithm=ball_tree, p=1, weights=distance, score=0.7832647462277091, total=   0.1s\n",
      "[CV] algorithm=ball_tree, p=1, weights=distance ......................\n",
      "[CV]  algorithm=ball_tree, p=1, weights=distance, score=0.7704618198445359, total=   0.1s\n",
      "[CV] algorithm=ball_tree, p=1, weights=distance ......................\n",
      "[CV]  algorithm=ball_tree, p=1, weights=distance, score=0.7554945054945055, total=   0.1s\n",
      "[CV] algorithm=ball_tree, p=2, weights=uniform .......................\n",
      "[CV]  algorithm=ball_tree, p=2, weights=uniform, score=0.7649748513946045, total=   0.1s\n",
      "[CV] algorithm=ball_tree, p=2, weights=uniform .......................\n",
      "[CV]  algorithm=ball_tree, p=2, weights=uniform, score=0.7754915409236397, total=   0.1s\n",
      "[CV] algorithm=ball_tree, p=2, weights=uniform .......................\n",
      "[CV]  algorithm=ball_tree, p=2, weights=uniform, score=0.7554945054945055, total=   0.1s\n",
      "[CV] algorithm=ball_tree, p=2, weights=distance ......................\n",
      "[CV]  algorithm=ball_tree, p=2, weights=distance, score=0.7700045724737082, total=   0.1s\n",
      "[CV] algorithm=ball_tree, p=2, weights=distance ......................\n",
      "[CV]  algorithm=ball_tree, p=2, weights=distance, score=0.7750342935528121, total=   0.1s\n",
      "[CV] algorithm=ball_tree, p=2, weights=distance ......................\n",
      "[CV]  algorithm=ball_tree, p=2, weights=distance, score=0.75, total=   0.1s\n",
      "[CV] algorithm=kd_tree, p=1, weights=uniform .........................\n",
      "[CV]  algorithm=kd_tree, p=1, weights=uniform, score=0.7850937357110197, total=   0.0s\n",
      "[CV] algorithm=kd_tree, p=1, weights=uniform .........................\n",
      "[CV]  algorithm=kd_tree, p=1, weights=uniform, score=0.7745770461819844, total=   0.0s\n",
      "[CV] algorithm=kd_tree, p=1, weights=uniform .........................\n",
      "[CV]  algorithm=kd_tree, p=1, weights=uniform, score=0.7568681318681318, total=   0.0s\n",
      "[CV] algorithm=kd_tree, p=1, weights=distance ........................\n",
      "[CV]  algorithm=kd_tree, p=1, weights=distance, score=0.7832647462277091, total=   0.0s\n",
      "[CV] algorithm=kd_tree, p=1, weights=distance ........................\n",
      "[CV]  algorithm=kd_tree, p=1, weights=distance, score=0.7704618198445359, total=   0.0s\n",
      "[CV] algorithm=kd_tree, p=1, weights=distance ........................\n",
      "[CV]  algorithm=kd_tree, p=1, weights=distance, score=0.7554945054945055, total=   0.0s\n",
      "[CV] algorithm=kd_tree, p=2, weights=uniform .........................\n",
      "[CV]  algorithm=kd_tree, p=2, weights=uniform, score=0.7649748513946045, total=   0.0s\n",
      "[CV] algorithm=kd_tree, p=2, weights=uniform .........................\n",
      "[CV]  algorithm=kd_tree, p=2, weights=uniform, score=0.7754915409236397, total=   0.0s\n",
      "[CV] algorithm=kd_tree, p=2, weights=uniform .........................\n",
      "[CV]  algorithm=kd_tree, p=2, weights=uniform, score=0.7554945054945055, total=   0.0s\n",
      "[CV] algorithm=kd_tree, p=2, weights=distance ........................\n",
      "[CV]  algorithm=kd_tree, p=2, weights=distance, score=0.7700045724737082, total=   0.0s\n",
      "[CV] algorithm=kd_tree, p=2, weights=distance ........................\n",
      "[CV]  algorithm=kd_tree, p=2, weights=distance, score=0.7750342935528121, total=   0.0s\n",
      "[CV] algorithm=kd_tree, p=2, weights=distance ........................\n",
      "[CV]  algorithm=kd_tree, p=2, weights=distance, score=0.75, total=   0.0s\n",
      "[CV] algorithm=brute, p=1, weights=uniform ...........................\n",
      "[CV]  algorithm=brute, p=1, weights=uniform, score=0.7850937357110197, total=   0.2s\n",
      "[CV] algorithm=brute, p=1, weights=uniform ...........................\n",
      "[CV]  algorithm=brute, p=1, weights=uniform, score=0.7745770461819844, total=   0.2s\n",
      "[CV] algorithm=brute, p=1, weights=uniform ...........................\n",
      "[CV]  algorithm=brute, p=1, weights=uniform, score=0.7568681318681318, total=   0.2s\n",
      "[CV] algorithm=brute, p=1, weights=distance ..........................\n",
      "[CV]  algorithm=brute, p=1, weights=distance, score=0.7832647462277091, total=   0.2s\n",
      "[CV] algorithm=brute, p=1, weights=distance ..........................\n",
      "[CV]  algorithm=brute, p=1, weights=distance, score=0.7704618198445359, total=   0.2s\n",
      "[CV] algorithm=brute, p=1, weights=distance ..........................\n",
      "[CV]  algorithm=brute, p=1, weights=distance, score=0.7554945054945055, total=   0.2s\n",
      "[CV] algorithm=brute, p=2, weights=uniform ...........................\n",
      "[CV]  algorithm=brute, p=2, weights=uniform, score=0.7649748513946045, total=   0.1s\n",
      "[CV] algorithm=brute, p=2, weights=uniform ...........................\n",
      "[CV]  algorithm=brute, p=2, weights=uniform, score=0.7754915409236397, total=   0.1s\n",
      "[CV] algorithm=brute, p=2, weights=uniform ...........................\n",
      "[CV]  algorithm=brute, p=2, weights=uniform, score=0.7554945054945055, total=   0.2s\n",
      "[CV] algorithm=brute, p=2, weights=distance ..........................\n",
      "[CV]  algorithm=brute, p=2, weights=distance, score=0.7700045724737082, total=   0.2s\n",
      "[CV] algorithm=brute, p=2, weights=distance ..........................\n",
      "[CV]  algorithm=brute, p=2, weights=distance, score=0.7750342935528121, total=   0.1s\n",
      "[CV] algorithm=brute, p=2, weights=distance ..........................\n",
      "[CV]  algorithm=brute, p=2, weights=distance, score=0.75, total=   0.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  36 out of  36 | elapsed:   19.1s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv='warn', error_score='raise-deprecating',\n",
       "       estimator=KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
       "           metric_params=None, n_jobs=None, n_neighbors=25, p=2,\n",
       "           weights='uniform'),\n",
       "       fit_params=None, iid='warn', n_jobs=None,\n",
       "       param_grid={'weights': ['uniform', 'distance'], 'algorithm': ['ball_tree', 'kd_tree', 'brute'], 'p': [1, 2]},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
       "       scoring=None, verbose=3)"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fit knn model using grid search estimator\n",
    "grid_knn.fit(X_train_scaled_mms, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'algorithm': 'ball_tree', 'p': 1, 'weights': 'uniform'}\n"
     ]
    }
   ],
   "source": [
    "# List the best parameters for this dataset\n",
    "print(grid_knn.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Data Score: 0.8007014333638305\n",
      "Testing Data Score: 0.7891125343092407\n"
     ]
    }
   ],
   "source": [
    "# Scores for train and test data after hyperparameter tuning of the model\n",
    "print(f\"Training Data Score: {grid_knn.score(X_train_scaled_mms, y_train)}\")\n",
    "print(f\"Testing Data Score: {grid_knn.score(X_test_scaled_mms, y_test)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.61      0.43      0.51       510\n",
      "           1       0.60      0.76      0.67       587\n",
      "           2       0.98      0.97      0.97      1089\n",
      "\n",
      "   micro avg       0.79      0.79      0.79      2186\n",
      "   macro avg       0.73      0.72      0.72      2186\n",
      "weighted avg       0.79      0.79      0.78      2186\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Calculate classification report\n",
    "print(classification_report(\n",
    "    y_test, grid_knn.predict(X_test_scaled_mms), target_names=[\"0\", \"1\", \"2\"]\n",
    "))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>target_test</th>\n",
       "      <th>target_predicted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>FALSE POSITIVE</td>\n",
       "      <td>FALSE POSITIVE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>FALSE POSITIVE</td>\n",
       "      <td>FALSE POSITIVE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>CONFIRMED</td>\n",
       "      <td>CONFIRMED</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>CANDIDATE</td>\n",
       "      <td>CONFIRMED</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>FALSE POSITIVE</td>\n",
       "      <td>FALSE POSITIVE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>CONFIRMED</td>\n",
       "      <td>CONFIRMED</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>CANDIDATE</td>\n",
       "      <td>CONFIRMED</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>FALSE POSITIVE</td>\n",
       "      <td>FALSE POSITIVE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>FALSE POSITIVE</td>\n",
       "      <td>FALSE POSITIVE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>FALSE POSITIVE</td>\n",
       "      <td>CANDIDATE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>CONFIRMED</td>\n",
       "      <td>CONFIRMED</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>CANDIDATE</td>\n",
       "      <td>CONFIRMED</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>FALSE POSITIVE</td>\n",
       "      <td>FALSE POSITIVE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>CONFIRMED</td>\n",
       "      <td>CONFIRMED</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>CANDIDATE</td>\n",
       "      <td>CANDIDATE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>CANDIDATE</td>\n",
       "      <td>CANDIDATE</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       target_test target_predicted\n",
       "0   FALSE POSITIVE   FALSE POSITIVE\n",
       "1   FALSE POSITIVE   FALSE POSITIVE\n",
       "2        CONFIRMED        CONFIRMED\n",
       "3        CANDIDATE        CONFIRMED\n",
       "4   FALSE POSITIVE   FALSE POSITIVE\n",
       "5        CONFIRMED        CONFIRMED\n",
       "6        CANDIDATE        CONFIRMED\n",
       "7   FALSE POSITIVE   FALSE POSITIVE\n",
       "8   FALSE POSITIVE   FALSE POSITIVE\n",
       "9   FALSE POSITIVE        CANDIDATE\n",
       "10       CONFIRMED        CONFIRMED\n",
       "11       CANDIDATE        CONFIRMED\n",
       "12  FALSE POSITIVE   FALSE POSITIVE\n",
       "13       CONFIRMED        CONFIRMED\n",
       "14       CANDIDATE        CANDIDATE\n",
       "15       CANDIDATE        CANDIDATE"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# DataFrame for test and predicted data\n",
    "target_pred_test_knn = pd.DataFrame({\n",
    "    \"target_test\": target_encoder.inverse_transform(y_test),\n",
    "    \"target_predicted\": target_encoder.inverse_transform(grid_knn.predict(X_test_scaled_mms))\n",
    "})\n",
    "\n",
    "# Preview \"target_pred_test_knn\"\n",
    "target_pred_test_knn.head(16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['../models/kepler_knn_model.h5']"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Save model as .h5 file\n",
    "joblib.dump(grid_knn.best_estimator_, '../models/kepler_knn_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernel_info": {
   "name": "dev"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  },
  "nteract": {
   "version": "0.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
